DEAI 引擎 2.0：深度语义与结构进化计划

  版本：2.0 (Proposed)
  核心目标：从单一的“关键词+规则”检测，进化为“词汇+句法+信息密度”的三维深度防御系统。
  适用范围：覆盖从分析内核 (core) 到 前端交互 (frontend) 及 LLM 交互 (suggester) 的全链路。

  ---

  1. 总体架构：三层防御模型 (The 3-Layer Defense)

  我们将检测逻辑重构为三个层级，层层递进，既保留了“一票否决”的 P0 词，又增加了对抗高级 AI 润色的能力。

   * Layer 1 (L1): 硬性词汇指纹 (Lexical Hard-Check) - 保留并强化
       * 针对：P0 级“死罪”词汇 (e.g., delve, realm, tapestry)。
       * 处理：直接标记高风险，无需复杂计算。
   * Layer 2 (L2): 句法空洞检测 (Syntactic Void Detection) - 新增
       * 针对：语法正确但内容空洞的“废话文学” (e.g., X plays a pivotal role in the comprehensive landscape of Y).
       * 处理：基于 spaCy 依存句法树，检测“抽象动词+抽象名词”链条。
   * Layer 3 (L3): 信息密度与逻辑锚点 (Density & Anchors) - 新增
       * 针对：逻辑线性平推、缺乏数据支撑的段落。
       * 处理：计算实词密度熵，寻找“学术锚点”（数据/引用/专有名词）。

  ---

  2. 详细改进实施方案

  2.1 模块改进：核心分析器 (src/core/analyzer)

  A. 强化指纹检测 (fingerprint.py) - 合并 P0 与 句法分析

  保留你现有的 P0 列表，但引入上下文免疫和句法模式。

  实现逻辑：
   1. Strict P0 Mode: 保持原有的 High-Freq Words 列表。凡是出现 delve, underscore (作动词), paramount，直接 Risk + 1.0。
   2. Contextual Logic (上下文免疫):
       * 如果 P0 词周围 5 个 token 内出现了 Academic Anchor (如具体的数字、化学式、引用 [1])，降低风险权重。
       * 例子: "The study delves into..." (高风险) vs "We delve into the dataset containing 500 samples..." (中风险)。
   3. Syntactic Pattern (新增功能):
       * 使用 spaCy 匹配模式：VERB(abstract) + dobj + NOUN(abstract)。
       * 检测 AI 惯用的“华丽空洞结构”。

    1 # 伪代码示例：src/core/analyzer/fingerprint.py
    2 class EnhancedFingerprintDetector:
    3     def detect_syntactic_voids(self, doc):
    4         # 定义抽象空洞模式
    5         # Pattern: "It is important to note" 变体
    6         # Pattern: "serves as a testament to"
    7         matcher = Matcher(self.nlp.vocab)
    8         pattern = [
    9             {"POS": "VERB", "LEMMA": {"IN": ["underscore", "highlight", "exemplify"]}},
   10             {"POS": "NOUN", "LEMMA": {"IN": ["significance", "importance", "nuance"]}},
   11             {"POS": "ADP", "LOWER": "of"}
   12         ]
   13         # ... 匹配并标记为 "Syntactic Filler" (句法填充物)

  B. 逻辑与密度分析 (paragraph_logic.py & scorer.py)

  AI 文本的一大特征是：看起来很顺，但单位字数内的信息量（Information Entropy）很低。

  实现逻辑：
   1. Burstiness (突发性) 的轻量化实现:
       * 不调用 GPT，而是计算 Uncommon Word Interval (罕见词间隔)。人类写作会密集使用罕见词（专业术语），然后是长段的常用词解释；AI 分布更均匀。
   2. 学术锚点密度 (Anchor Density):
       * 扫描段落中的：数字, 带单位的量, 引用符号, 大写专有名词。
       * 规则: 如果一个长段落（>50词）的 Anchor Density < 5%，标记为 "Hallucination Risk" (幻觉风险)，即“这可能是 AI 编造的套话”。

  2.2 模块改进：提示词生成系统 (src/core/suggester)

  这是最需要改进的地方。目前的提示词可能只是“请重写这段话”。我们需要基于诊断结果动态生成提示词。

  实现逻辑：
  根据分析模块输出的 Issue Type 组装 Prompt。


  ┌───────────────────────┬─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
  ─┐
  │ 诊断出的问题 (Diag... │ 动态生成的提示词策略 (Dynamic Prompt Strategy)
  │
  ├───────────────────────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
  ─┤
  │ P0 Fingerprint (e.... │ "Replace the word 'delve' with a concrete action verb describing the methodology (e.g., 'analyzed', 'investigated'). Do not use flowe...
  │
  │ Syntactic Void (废话) │ "The sentence '[Target Sentence]' is syntactically complex but semantically empty. Rewrite it to succinctly state the specific findin...
  │
  │ Linear Logic (流水账) │ "This paragraph follows a linear 'List' structure. Reorganize it using a 'Contrastive' or 'Causal' structure to better connect the ar...
  │
  │ **Low Anchor Densi... │ "This section lacks specific evidence. Rewrite it to include placeholders like '[DATA]' or '[QUANTITY]' where specific values should ...
  │
  └───────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
  ─┘


  代码行动点:
  修改 src/core/suggester/prompts，创建一个 PromptBuilder 类，接受 AnalysisReport 对象作为输入，而不是仅仅接受原始文本。

  2.3 模块改进：AI 修改合并 (src/core/suggester/llm_track.py)

  目前的合并可能只是简单的文本替换。对于 P0 级指纹的修改，我们需要更智能的合并策略，防止 AI 在重写时把 P0 词又改回去了（或者换成了另一个 P0 词）。

  实现逻辑：
   1. Post-Generation Check (生成后自检):
       * LLM 生成建议文本后，立即再次运行 `FingerprintDetector`。
       * 如果生成的建议中包含 P0 词（例如把 delve 改成了 tapestry），自动拒绝该建议或强制重试，不展示给用户。
       * 这是防止“越改越AI”的关键守门员。
   2. Structural Diff:
       * 如果只是替换单词，使用高亮标记。
       * 如果是重构句子，提供 Before/After 的结构对比视图。

  2.4 模块改进：解决方案提供 (src/core/validator)

  除了调用 LLM，系统应该提供确定性的 (Deterministic) 解决方案。

  实现逻辑：
   1. P0 词的硬编码映射:
       * 建立一个 SafeReplacementDB (安全替换库)。
       * Input: "delve" -> Output: ["investigate", "examine", "analyze"] (提供给用户的快速下拉菜单)。
   2. 句式模板库:
       * 针对常见的 AI 句式（如 "It is important to note..."），提供“删除并提炼”的自动操作（Auto-fix），即直接删除该短语，并将后面的首字母大写。

  ---

  3. 具体的开发 Roadmap

  Phase 1: 强化检测核心 (The Eye)
   1. 更新 `fingerprint.py`:
       * [ ] 集成 spaCy 模型。
       * [ ] 实现 ContextualFilter (检测周围是否有 Anchor)。
       * [ ] 实现 SyntacticVoidDetector (检测空洞结构)。
   2. 更新 `scorer.py`:
       * [ ] 实现 AnchorDensityCalculator (锚点密度计算)。

  Phase 2: 动态诊疗 (The Brain)
   1. 重构 `prompts/structure_deaigc.py`:
       * [ ] 将 Prompt 静态字符串改为 Jinja2 模板。
       * [ ] 编写逻辑，根据 Phase 1 检测出的 flag (如 has_p0_word, is_linear) 填充模板。

  Phase 3: 质量控制与闭环 (The Gatekeeper)
   1. 更新 `llm_track.py`:
       * [ ] 添加 verify_suggestion() 函数：在返回给前端前，检查建议本身是否含指纹。
       * [ ] 建立 P0 词的 Blocklist，严禁 LLM 输出这些词。

  ---

  4. 总结

  这个改进计划的核心思想是：“知其然 (检测 P0)，知其所以然 (检测逻辑空洞)，并控制解决过程 (Prompt 动态化 + 结果自检)”。

  如果不这样做，你的工具可能只是一个“高级查词典软件”；做了这个，它就是一个“具备学术鉴赏力的 AI 编辑”。