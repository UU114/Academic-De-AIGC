# Layer 1 (Lexical Level) Sub-Step System Design
# ç¬¬1å±‚ï¼ˆè¯æ±‡çº§ï¼‰å­æ­¥éª¤ç³»ç»Ÿè®¾è®¡

> Version: 1.0
> Date: 2026-01-08
> Purpose: Design comprehensive sub-step workflow for lexical-level De-AIGC processing with paragraph context
> ç›®çš„ï¼šè®¾è®¡åœ¨æ®µè½ä¸Šä¸‹æ–‡ä¸­è¿›è¡Œè¯æ±‡çº§De-AIGCå¤„ç†çš„å®Œæ•´å­æ­¥éª¤å·¥ä½œæµç¨‹

---

## ä¸€ã€è®¾è®¡æ¦‚è¿° | Design Overview

### 1.1 å±‚çº§å®šä½ | Layer Positioning

```
Layer 5: Document (æ–‡ç« å±‚)     â†’ Step 1.x series âœ… å·²å®ç°
Layer 4: Section (ç« èŠ‚å±‚)      â†’ Step 2.x series âœ… å·²å®ç°
Layer 3: Paragraph (æ®µè½å±‚)    â†’ Step 3.x series âœ… å·²å®ç°
Layer 2: Sentence (å¥å­å±‚)     â†’ Step 4.x series âœ… å·²è®¾è®¡
Layer 1: Lexical (è¯æ±‡å±‚)      â†’ Step 5.x series ğŸ“‹ æœ¬æ–‡æ¡£è®¾è®¡
```

### 1.2 Layer 1 æ ¸å¿ƒè®¾è®¡ç†å¿µ | Core Design Philosophy

**é‡è¦åŸåˆ™**ï¼šLayer 1 **ä¸æ˜¯**ç®€å•åœ°æ›¿æ¢å•ä¸ªè¯æ±‡ï¼Œè€Œæ˜¯**åœ¨æ®µè½å°ºåº¦ä¸Š**ç»¼åˆåˆ†æè¯æ±‡é—®é¢˜ï¼š
- æŒ‰æ®µè½ä¸ºå•ä½ç»Ÿè®¡AIGCæŒ‡çº¹è¯åˆ†å¸ƒ
- åˆ†æäººç±»å†™ä½œè¯æ±‡çš„è¦†ç›–ç‡
- åœ¨ä¿æŠ¤é”å®šè¯æ±‡çš„å‰æä¸‹è¿›è¡Œæ”¹å†™
- å…ˆåˆ†æé—®é¢˜ï¼Œå†åˆ©ç”¨AIè¿›è¡Œde-AIGCæ”¹å†™
- æ”¹å†™åŒæ—¶å¢åŠ äººç±»å†™ä½œç‰¹å¾
- ç¡®ä¿å­¦æœ¯å†™ä½œçš„ä¸¥è°¨æ€§

**æ ¸å¿ƒæ“ä½œ**ï¼š
| æ“ä½œç±»å‹ | è¯´æ˜ Description | ç›®æ ‡ Goal |
|---------|-----------------|----------|
| **æ£€æµ‹AIGCæŒ‡çº¹** | è¯†åˆ«AIç‰¹å¾è¯æ±‡å’ŒçŸ­è¯­ | å®šä½é£é™©ç‚¹ |
| **åˆ†æäººç±»ç‰¹å¾ç¼ºå¤±** | æ£€æµ‹äººç±»å†™ä½œç‰¹å¾è¯æ±‡ç¼ºå¤± | è¯†åˆ«æå‡ç©ºé—´ |
| **ç”Ÿæˆæ›¿æ¢å€™é€‰** | ä¸ºæŒ‡çº¹è¯ç”Ÿæˆä¸Šä¸‹æ–‡é€‚é…çš„æ›¿æ¢æ–¹æ¡ˆ | å‡†å¤‡æ”¹å†™ç´ æ |
| **LLMæ®µè½çº§æ”¹å†™** | æŒ‰æ®µè½ä¸ºå•ä½ï¼Œç»¼åˆæ”¹å†™é™ä½AIç‰¹å¾ | æ¶ˆé™¤æŒ‡çº¹ |
| **å¢åŠ äººç±»ç‰¹å¾** | æ³¨å…¥äººç±»å­¦æœ¯å†™ä½œç‰¹å¾è¯æ±‡ | å¢å¼ºè‡ªç„¶åº¦ |
| **éªŒè¯å­¦æœ¯ä¸¥è°¨æ€§** | ç¡®ä¿æ”¹å†™ä¿æŒå­¦æœ¯è§„èŒƒ | è´¨é‡ä¿éšœ |

### 1.3 ä¸ç›¸é‚»å±‚çš„å…³ç³» | Relationship with Adjacent Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Layer 2 (Sentence)                           â”‚
â”‚  â”œâ”€â”€ ä¼ å…¥: sentences[], sentence_contexts[]                        â”‚
â”‚  â”œâ”€â”€ ä¼ å…¥: sentence_roles[], paragraph_sentence_map                â”‚
â”‚  â””â”€â”€ ä¼ å…¥: pattern_issues[], connector_issues[]                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Layer 1 (Lexical)                              â”‚
â”‚  â”œâ”€â”€ æ¥æ”¶: å¥å­ä¸Šä¸‹æ–‡ (roles, patterns, positions)                  â”‚
â”‚  â”œâ”€â”€ æ¥æ”¶: é”å®šè¯æ±‡ (locked_terms from Step 1.0)                    â”‚
â”‚  â”œâ”€â”€ åˆ†æ: æ®µè½å†…çš„AIGCæŒ‡çº¹è¯åˆ†å¸ƒ                                    â”‚
â”‚  â”œâ”€â”€ åˆ†æ: äººç±»å†™ä½œç‰¹å¾è¯æ±‡è¦†ç›–                                      â”‚
â”‚  â”œâ”€â”€ æ“ä½œ: ç”Ÿæˆæ›¿æ¢å€™é€‰ã€LLMæ”¹å†™ã€äººç±»ç‰¹å¾æ³¨å…¥                       â”‚
â”‚  â””â”€â”€ ä¼ å‡º: final_text + analysis_report                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
                        æœ€ç»ˆè¾“å‡º Final Output
```

---

## äºŒã€AIGCä¸äººç±»è¯æ±‡ç‰¹å¾åº“ | AIGC vs Human Vocabulary Feature Database

### 2.1 AIGCæŒ‡çº¹è¯æ±‡åˆ†ç±» | AIGC Fingerprint Word Categories

åŸºäº `words.csv` å’Œ `AIGC_vs_Human_Academic_Lexicon.xlsx` çš„ç»Ÿè®¡è§„å¾‹ï¼š

#### 2.1.1 Type A: æ­»è¯è¯ (Dead Giveaways) - é£é™©æƒé‡ +40

| è¯æ±‡ Word | æƒé‡ Weight | ç±»å‹ Type | å…¸å‹ä¸Šä¸‹æ–‡ Context |
|-----------|-------------|-----------|-------------------|
| delve (into) | 99 | Verb | å¸¸ç”¨äºIntroduction |
| underscore | 95 | Verb | ç”¨äºè¿‡åº¦å¼ºè°ƒ |
| harness | 92 | Verb | "harnessing power/potential" |
| unveil | 87 | Verb | æ­ç¤ºæ–°æ¦‚å¿µ |
| pivotal | 98 | Adjective | "è‡³å…³é‡è¦" |
| intricate | 96 | Adjective | "å¤æ‚çš„ç»†èŠ‚" |
| multifaceted | 94 | Adjective | "å¤šæ–¹é¢çš„" |
| paramount | 88 | Adjective | "æœ€é‡è¦çš„" |
| tapestry | 93 | Noun | æŠ½è±¡ç»„åˆæ¯”å–» |
| realm | 95 | Noun | "é¢†åŸŸ" |
| landscape | 97 | Noun | ç¯å¢ƒæ¯”å–» |

#### 2.1.2 Type B: å­¦æœ¯é™ˆè¯ (Academic ClichÃ©s) - é£é™©æƒé‡ +5-25

| è¯æ±‡ Word | æƒé‡ Weight | ç±»å‹ Type | äººç±»æ›¿ä»£ Human Alternative |
|-----------|-------------|-----------|---------------------------|
| comprehensive | 91 | Adjective | thorough, full, complete |
| robust | 89 | Adjective | strong, reliable, solid |
| seamless | 86 | Adjective | smooth, integrated |
| leverage | 90 | Verb | use, apply, employ |
| facilitate | 84 | Verb | help, enable, support |
| utilize | - | Verb | use, apply |
| crucial | 85 | Adjective | important, key, essential |
| holistic | 85 | Adjective | complete, whole, integrated |
| transformative | 84 | Adjective | significant, major |

#### 2.1.3 Type C: æŒ‡çº¹çŸ­è¯­ (Fingerprint Phrases) - é£é™©æƒé‡ +15-35

| çŸ­è¯­ Phrase | æƒé‡ Weight | äººç±»æ›¿ä»£ Human Alternative |
|-------------|-------------|---------------------------|
| In conclusion | 99 | To conclude, Ultimately, Finally |
| Important to note | 96 | Notably, Note that |
| Not only...but also | 94 | Beyond X, Y. / X. Also, Y. |
| Ever-evolving | 95 | Changing, Developing |
| Crucial role | 92 | Important role, Key function |
| In the realm of | 30 | In, Within, Regarding |
| A plethora of | 82 | Many, Numerous, Various |
| Pave the way | 88 | Enable, Allow, Facilitate |
| Shed light on | 88 | Explain, Clarify, Reveal |

### 2.2 äººç±»å­¦æœ¯å†™ä½œç‰¹å¾è¯æ±‡ | Human Academic Writing Features

åŸºäº `words.csv` ä¸­ Human ç±»åˆ«çš„ç»Ÿè®¡ï¼š

#### 2.2.1 é«˜é¢‘åŠ¨è¯ (High-frequency Verbs) - ç›®æ ‡è¦†ç›–ç‡ â‰¥15%

| è¯æ±‡ Word | æƒé‡ Weight | ç”¨æ³• Usage |
|-----------|-------------|-----------|
| examine | 95 | å…·ä½“ç ”ç©¶ |
| argue | 92 | é™ˆè¿°ç«‹åœº |
| suggest | 90 | è°¨æ…ç»“è®º |
| demonstrate | 87 | å±•ç¤ºè¯æ® |
| observe | 86 | è®°å½•æ•°æ® |
| identify | 84 | ç²¾ç¡®å®šä½ |
| investigate | 88 | æ·±å…¥ç ”ç©¶ |
| analyze | 88 | æ•°æ®åˆ†æ |
| validate | 82 | éªŒè¯ç¡®è®¤ |
| assess | 84 | è¯„ä¼°åˆ¤æ–­ |

#### 2.2.2 å­¦æœ¯å½¢å®¹è¯ (Academic Adjectives) - ç›®æ ‡è¦†ç›–ç‡ â‰¥10%

| è¯æ±‡ Word | æƒé‡ Weight | ç”¨æ³• Usage |
|-----------|-------------|-----------|
| significant | 98 | ç»Ÿè®¡æ„ä¹‰ |
| associated (with) | 96 | ç›¸å…³æ€§ |
| specific | 94 | ç²¾ç¡®çš„ |
| empirical | 92 | åŸºäºæ•°æ® |
| consistent | 90 | ä¸€è‡´çš„ |
| preliminary | 85 | åˆæ­¥é˜¶æ®µ |
| quantitative | 90 | å®šé‡çš„ |
| qualitative | 90 | å®šæ€§çš„ |
| limited | 88 | èŒƒå›´é™åˆ¶ |

#### 2.2.3 å­¦æœ¯çŸ­è¯­ (Academic Phrases) - ç›®æ ‡è¦†ç›–ç‡ â‰¥5%

| çŸ­è¯­ Phrase | æƒé‡ Weight | ç”¨æ³• Usage |
|-------------|-------------|-----------|
| Results indicate | 95 | æ•°æ®é©±åŠ¨ |
| In contrast to | 94 | å¯¹æ¯” |
| To our knowledge | 92 | èŒƒå›´é™å®š |
| Data suggest | 89 | è¯æ®æ”¯æŒ |
| Consistent with | 88 | æ–‡çŒ®å¯¹é½ |
| Future research | 87 | ä¸‹ä¸€æ­¥ |
| Standard deviation | 90 | ç»Ÿè®¡æœ¯è¯­ |
| Account for | 82 | è§£é‡ŠåŸå›  |

### 2.3 æ£€æµ‹æŒ‡æ ‡é˜ˆå€¼ | Detection Metric Thresholds

| æŒ‡æ ‡ Metric | AIç‰¹å¾é˜ˆå€¼ | äººç±»ç‰¹å¾ç›®æ ‡ | è¯´æ˜ |
|------------|-----------|-------------|------|
| Type AæŒ‡çº¹è¯æ•°é‡ | > 0 | = 0 | æ­»è¯è¯å¿…é¡»æ¸…é™¤ |
| Type BæŒ‡çº¹è¯å¯†åº¦ | > 2% | < 1% | æ¯100è¯ä¸­çš„å æ¯” |
| Type CçŸ­è¯­æ•°é‡ | > 3 | â‰¤ 1 | æ¯1000è¯ |
| äººç±»åŠ¨è¯è¦†ç›–ç‡ | < 10% | â‰¥ 15% | ç›®æ ‡è¯æ±‡è¦†ç›– |
| äººç±»å½¢å®¹è¯è¦†ç›–ç‡ | < 5% | â‰¥ 10% | ç›®æ ‡è¯æ±‡è¦†ç›– |
| äººç±»çŸ­è¯­å‡ºç°ç‡ | < 2% | â‰¥ 5% | ç›®æ ‡çŸ­è¯­å‡ºç° |

---

## ä¸‰ã€å­æ­¥éª¤è®¾è®¡æ–¹æ¡ˆ | Sub-Step Design Proposal

### 3.0 æ‰§è¡Œæµç¨‹å›¾ | Execution Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Layer 1: Lexical Level Analysis                           â”‚
â”‚                    è¯æ±‡çº§åˆ†æï¼ˆåŸºäºæ®µè½ä¸Šä¸‹æ–‡ï¼Œå…ˆåˆ†æåæ”¹å†™ï¼‰                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Step 5.0: è¯æ±‡ç¯å¢ƒå‡†å¤‡ (Lexical Context Preparation)              â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ æ¥æ”¶å¥å­å±‚ä¸Šä¸‹æ–‡ Receive sentence context from Layer 2        â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ ç»§æ‰¿é”å®šè¯æ±‡åˆ—è¡¨ Inherit locked terms from Step 1.0           â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ å»ºç«‹æ®µè½-è¯æ±‡æ˜ å°„ Build paragraph-term mapping                â”‚     â”‚
â”‚  â”‚  â””â”€â”€ åŠ è½½è¯æ±‡ç‰¹å¾åº“ Load vocabulary feature database               â”‚     â”‚
â”‚  â”‚                                                                     â”‚     â”‚
â”‚  â”‚  æ£€æµ‹å™¨ï¼šContextLoader                                              â”‚     â”‚
â”‚  â”‚  è¾“å‡ºï¼šparagraph_term_map{}, locked_terms[], feature_db             â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                    â†“                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Step 5.1: AIGCæŒ‡çº¹è¯æ£€æµ‹ (AIGC Fingerprint Detection)             â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ Type Aæ­»è¯è¯æ£€æµ‹ Detect Dead Giveaway words                   â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ Type Bå­¦æœ¯é™ˆè¯æ£€æµ‹ Detect Academic ClichÃ© words               â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ Type CæŒ‡çº¹çŸ­è¯­æ£€æµ‹ Detect Fingerprint phrases                 â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ æŒ‰æ®µè½ç»Ÿè®¡åˆ†å¸ƒ Per-paragraph distribution statistics          â”‚     â”‚
â”‚  â”‚  â””â”€â”€ æ’é™¤é”å®šè¯æ±‡ Exclude locked terms from detection              â”‚     â”‚
â”‚  â”‚                                                                     â”‚     â”‚
â”‚  â”‚  æ£€æµ‹å™¨ï¼šFingerprintDetector (Enhanced)                            â”‚     â”‚
â”‚  â”‚  è¾“å‡ºï¼šfingerprint_issues[], density_per_para{}, risk_score        â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                    â†“                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Step 5.2: äººç±»ç‰¹å¾è¯æ±‡åˆ†æ (Human Feature Vocabulary Analysis)    â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ æ£€æµ‹äººç±»å­¦æœ¯åŠ¨è¯è¦†ç›– Detect human academic verb coverage      â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ æ£€æµ‹äººç±»å½¢å®¹è¯è¦†ç›– Detect human adjective coverage            â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ æ£€æµ‹äººç±»çŸ­è¯­å‡ºç°ç‡ Detect human phrase occurrence             â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ è®¡ç®—äººç±»ç‰¹å¾å¾—åˆ† Calculate human feature score                â”‚     â”‚
â”‚  â”‚  â””â”€â”€ è¯†åˆ«å¯æ³¨å…¥äººç±»ç‰¹å¾çš„ä½ç½® Identify injection points            â”‚     â”‚
â”‚  â”‚                                                                     â”‚     â”‚
â”‚  â”‚  æ£€æµ‹å™¨ï¼šHumanFeatureAnalyzer (NEW)                                â”‚     â”‚
â”‚  â”‚  è¾“å‡ºï¼šhuman_coverage{}, feature_score, injection_points[]         â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                    â†“                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Step 5.3: æ›¿æ¢å€™é€‰ç”Ÿæˆ (Replacement Candidate Generation)         â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ ä¸ºæ¯ä¸ªAIGCæŒ‡çº¹è¯ç”Ÿæˆå€™é€‰ Generate candidates per fingerprint  â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ è€ƒè™‘ä¸Šä¸‹æ–‡è¯­ä¹‰é€‚é… Consider contextual semantic fitness        â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ è€ƒè™‘å£è¯­åŒ–ç­‰çº§ Consider colloquialism level                   â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ ä¼˜å…ˆé€‰æ‹©äººç±»ç‰¹å¾è¯ Prefer human feature words                 â”‚     â”‚
â”‚  â”‚  â””â”€â”€ ç”Ÿæˆè§„åˆ™å»ºè®®(Track B) Generate rule-based suggestions         â”‚     â”‚
â”‚  â”‚                                                                     â”‚     â”‚
â”‚  â”‚  æ£€æµ‹å™¨ï¼šReplacementCandidateGenerator                             â”‚     â”‚
â”‚  â”‚  è¾“å‡ºï¼šreplacement_candidates{}, rule_suggestions[]                â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                    â†“                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Step 5.4: LLMæ®µè½çº§æ”¹å†™ (LLM Paragraph-Level Rewriting)           â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ æŒ‰æ®µè½ä¸ºå•ä½æ‰¹é‡æ”¹å†™ Batch rewrite by paragraph               â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ ä¼ å…¥AIGCé—®é¢˜åˆ†æ Pass AIGC issue analysis                     â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ ä¼ å…¥äººç±»ç‰¹å¾ç›®æ ‡ Pass human feature targets                   â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ ä¿æŠ¤é”å®šè¯æ±‡ Protect locked terms                             â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ åº”ç”¨å­¦æœ¯å†™ä½œè§„èŒƒ Apply academic writing norms                 â”‚     â”‚
â”‚  â”‚  â””â”€â”€ ç”ŸæˆLLMå»ºè®®(Track A) Generate LLM suggestions                 â”‚     â”‚
â”‚  â”‚                                                                     â”‚     â”‚
â”‚  â”‚  æ£€æµ‹å™¨ï¼šLLMParagraphRewriter                                      â”‚     â”‚
â”‚  â”‚  è¾“å‡ºï¼šrewritten_paragraphs[], llm_suggestions[], changes[]        â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                    â†“                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Step 5.5: æ”¹å†™ç»“æœéªŒè¯ (Rewrite Result Validation)                â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ è¯­ä¹‰ç›¸ä¼¼åº¦éªŒè¯ Semantic similarity validation (â‰¥0.85)        â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ AIGCé£é™©é™ä½è¯„ä¼° AIGC risk reduction assessment               â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ äººç±»ç‰¹å¾æå‡è¯„ä¼° Human feature improvement assessment         â”‚     â”‚
â”‚  â”‚  â”œâ”€â”€ å­¦æœ¯è§„èŒƒæ£€æŸ¥ Academic norm verification                       â”‚     â”‚
â”‚  â”‚  â””â”€â”€ é”å®šè¯æ±‡å®Œæ•´æ€§æ£€æŸ¥ Locked term integrity check                â”‚     â”‚
â”‚  â”‚                                                                     â”‚     â”‚
â”‚  â”‚  æ£€æµ‹å™¨ï¼šRewriteValidator                                          â”‚     â”‚
â”‚  â”‚  è¾“å‡ºï¼švalidation_results{}, final_paragraphs[], quality_report    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                    â†“                                         â”‚
â”‚                     è¾“å‡ºæœ€ç»ˆæ–‡æœ¬å’Œåˆ†ææŠ¥å‘Š Output final text & report        â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## å››ã€å„å­æ­¥éª¤è¯¦ç»†è®¾è®¡ | Detailed Design for Each Sub-Step

### Step 5.0: è¯æ±‡ç¯å¢ƒå‡†å¤‡ (Lexical Context Preparation)

**ç›®çš„ Purpose**ï¼šä½œä¸ºLayer 1çš„åŸºç¡€æ­¥éª¤ï¼Œæ¥æ”¶ä¸Šå±‚ä¸Šä¸‹æ–‡ï¼Œå‡†å¤‡è¯æ±‡åˆ†ææ‰€éœ€çš„ç¯å¢ƒã€‚

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
| åŠŸèƒ½ Function | è¯´æ˜ Description |
|--------------|------------------|
| æ¥æ”¶å¥å­å±‚ä¸Šä¸‹æ–‡ | ä»Layer 2æ¥æ”¶å¥å­åŠæ®µè½æ˜ å°„ |
| ç»§æ‰¿é”å®šè¯æ±‡ | ä»Step 1.0è·å–ç”¨æˆ·ç¡®è®¤çš„é”å®šè¯æ±‡åˆ—è¡¨ |
| å»ºç«‹æ®µè½-è¯æ±‡æ˜ å°„ | ä¸ºæ¯ä¸ªæ®µè½å»ºç«‹è¯æ±‡ç´¢å¼• |
| åŠ è½½è¯æ±‡ç‰¹å¾åº“ | åŠ è½½AIGCæŒ‡çº¹åº“å’Œäººç±»ç‰¹å¾åº“ |

**è¾“å…¥æ•°æ®ç»“æ„**ï¼š
```python
class LexicalContextRequest(BaseModel):
    document_text: str
    session_id: str  # Required for locked terms
    sentence_context: Optional[Dict]  # From Layer 2
        # sentences: List[SentenceInfo]
        # sentence_roles: List[str]
        # paragraph_sentence_map: Dict[int, List[int]]
    colloquialism_level: int = 4  # 0-10
```

**è¾“å‡ºæ•°æ®ç»“æ„**ï¼š
```python
class LexicalContextResponse(BaseModel):
    paragraphs: List[ParagraphLexicalInfo]
    locked_terms: List[str]
    total_words: int
    feature_db_loaded: bool

class ParagraphLexicalInfo(BaseModel):
    index: int
    text: str
    word_count: int
    sentences: List[str]
    word_positions: Dict[str, List[int]]  # word â†’ [positions]
```

---

### Step 5.1: AIGCæŒ‡çº¹è¯æ£€æµ‹ (AIGC Fingerprint Detection)

**ç›®çš„ Purpose**ï¼šæ£€æµ‹æ–‡æ¡£ä¸­çš„AIGCæŒ‡çº¹è¯æ±‡å’ŒçŸ­è¯­ï¼ŒæŒ‰æ®µè½ç»Ÿè®¡åˆ†å¸ƒï¼Œæ’é™¤é”å®šè¯æ±‡ã€‚

**æ£€æµ‹ç±»å‹**ï¼š
| ç±»å‹ Type | é£é™©æƒé‡ Risk | æ£€æµ‹æ–¹æ³• Method |
|----------|--------------|-----------------|
| Type A: æ­»è¯è¯ | +40/match | ç²¾ç¡®åŒ¹é…è¯å…¸ |
| Type B: å­¦æœ¯é™ˆè¯ | +5-25/match | ç²¾ç¡®åŒ¹é…è¯å…¸ |
| Type C: æŒ‡çº¹çŸ­è¯­ | +15-35/match | æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… |

**æ£€æµ‹é¡¹**ï¼š
| æ£€æµ‹é¡¹ Detection | è§¦å‘æ¡ä»¶ Trigger | é£é™©ç­‰çº§ Risk |
|-----------------|-----------------|---------------|
| æ­»è¯è¯å‡ºç° | Type A count > 0 | Critical |
| æŒ‡çº¹è¯å¯†åº¦é«˜ | density > 2% | High |
| æŒ‡çº¹çŸ­è¯­è¿‡å¤š | phrase count > 3/1000è¯ | High |
| æ®µè½æŒ‡çº¹é›†ä¸­ | å•æ®µå¯†åº¦ > 5% | Medium |

**é”å®šè¯æ±‡å¤„ç†**ï¼š
```python
# Locked terms are NEVER flagged as fingerprints
# Example: If "delve" is locked (technical term), skip detection
for fingerprint in detected_fingerprints:
    if any(locked.lower() in fingerprint.lower()
           for locked in locked_terms):
        continue  # Skip this fingerprint
```

**è¾“å‡ºæ•°æ®ç»“æ„**ï¼š
```python
class FingerprintDetectionResponse(BaseModel):
    total_fingerprints: int
    type_a_matches: List[FingerprintMatch]
    type_b_matches: List[FingerprintMatch]
    phrase_matches: List[PhraseMatch]
    density_per_paragraph: Dict[int, float]
    overall_density: float
    risk_score: int  # 0-100
    issues: List[DetectionIssue]

class FingerprintMatch(BaseModel):
    word: str
    count: int
    risk_weight: int
    paragraph_indices: List[int]
    positions: List[MatchPosition]
    is_locked: bool  # True if overlaps with locked term
```

**ç”¨æˆ·ç•Œé¢è®¾è®¡**ï¼š
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 5.1: AIGCæŒ‡çº¹è¯æ£€æµ‹ AIGC Fingerprint Detection              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ£€æµ‹ç»“æœ Detection Results:                                      â”‚
â”‚                                                                  â”‚
â”‚ æ•´ä½“æŒ‡çº¹å¯†åº¦: 3.2% [é«˜é£é™©] âš ï¸                                   â”‚
â”‚ æ•´ä½“é£é™©åˆ†æ•°: 72/100 [é«˜é£é™©]                                    â”‚
â”‚                                                                  â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Type A æ­»è¯è¯ (Dead Giveaways):                     4 ä¸ª    â”‚ â”‚
â”‚ â”‚ â”œâ”€â”€ "delve" Ã— 2 (Para 1, Para 5) [+80]                     â”‚ â”‚
â”‚ â”‚ â”œâ”€â”€ "tapestry" Ã— 1 (Para 3) [+40]                          â”‚ â”‚
â”‚ â”‚ â””â”€â”€ "multifaceted" Ã— 1 (Para 7) [+40]                      â”‚ â”‚
â”‚ â”‚                                                             â”‚ â”‚
â”‚ â”‚ Type B å­¦æœ¯é™ˆè¯ (Academic ClichÃ©s):                 8 ä¸ª    â”‚ â”‚
â”‚ â”‚ â”œâ”€â”€ "comprehensive" Ã— 3 [+30]                              â”‚ â”‚
â”‚ â”‚ â”œâ”€â”€ "robust" Ã— 2 [+30]                                     â”‚ â”‚
â”‚ â”‚ â””â”€â”€ "leverage" Ã— 3 [+45]                                   â”‚ â”‚
â”‚ â”‚                                                             â”‚ â”‚
â”‚ â”‚ Type C æŒ‡çº¹çŸ­è¯­ (Fingerprint Phrases):              3 ä¸ª    â”‚ â”‚
â”‚ â”‚ â”œâ”€â”€ "plays a crucial role" Ã— 2 [+60]                       â”‚ â”‚
â”‚ â”‚ â””â”€â”€ "in the realm of" Ã— 1 [+30]                            â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                  â”‚
â”‚ ğŸ”’ é”å®šè¯æ±‡å·²æ’é™¤: "methodology", "framework" (ä¸è®¡å…¥é£é™©)       â”‚
â”‚                                                                  â”‚
â”‚ æ®µè½åˆ†å¸ƒ Paragraph Distribution:                                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Para 1:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  4.5% âš ï¸ High                â”‚ â”‚
â”‚ â”‚ Para 2:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  2.1%                        â”‚ â”‚
â”‚ â”‚ Para 3:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘  5.8% âš ï¸âš ï¸ Critical          â”‚ â”‚
â”‚ â”‚ Para 4:  â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  1.2% âœ… Low                 â”‚ â”‚
â”‚ â”‚ Para 5:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  3.5% âš ï¸ High                â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                  â”‚
â”‚ [æŸ¥çœ‹è¯¦æƒ…] [ç»§ç»­ä¸‹ä¸€æ­¥ â†’]                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Step 5.2: äººç±»ç‰¹å¾è¯æ±‡åˆ†æ (Human Feature Vocabulary Analysis)

**ç›®çš„ Purpose**ï¼šåˆ†ææ–‡æ¡£ä¸­äººç±»å­¦æœ¯å†™ä½œç‰¹å¾è¯æ±‡çš„è¦†ç›–ç‡ï¼Œè¯†åˆ«å¯ä»¥å¢å¼ºäººç±»ç‰¹å¾çš„ä½ç½®ã€‚

**æ£€æµ‹ç»´åº¦**ï¼š
| ç»´åº¦ Dimension | ç›®æ ‡è¯æ±‡ Target | ç›®æ ‡è¦†ç›–ç‡ Target |
|---------------|----------------|------------------|
| å­¦æœ¯åŠ¨è¯ | examine, argue, suggest, demonstrate... | â‰¥15% |
| å­¦æœ¯å½¢å®¹è¯ | significant, empirical, specific... | â‰¥10% |
| å­¦æœ¯çŸ­è¯­ | "results indicate", "in contrast to"... | â‰¥5% |
| è°¨æ…è¡¨è¿° | "may", "could", "suggests", "appears"... | â‰¥8% |

**è¾“å‡ºæ•°æ®ç»“æ„**ï¼š
```python
class HumanFeatureAnalysisResponse(BaseModel):
    verb_coverage: CoverageStats
    adjective_coverage: CoverageStats
    phrase_coverage: CoverageStats
    hedging_coverage: CoverageStats
    overall_human_score: int  # 0-100
    feature_gaps: List[FeatureGap]
    injection_points: List[InjectionPoint]

class CoverageStats(BaseModel):
    target_words: List[str]
    found_words: List[str]
    found_count: int
    coverage_rate: float
    target_rate: float
    is_sufficient: bool

class InjectionPoint(BaseModel):
    paragraph_index: int
    sentence_index: int
    suggested_features: List[str]
    reason: str
    reason_zh: str
```

**ç”¨æˆ·ç•Œé¢è®¾è®¡**ï¼š
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 5.2: äººç±»ç‰¹å¾è¯æ±‡åˆ†æ Human Feature Vocabulary Analysis     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ äººç±»ç‰¹å¾å¾—åˆ† Human Feature Score: 38/100 [éœ€æ”¹è¿›]                â”‚
â”‚                                                                  â”‚
â”‚ ç‰¹å¾è¦†ç›–ç‡ Coverage Analysis:                                    â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ç±»åˆ«        â”‚ å½“å‰  â”‚ ç›®æ ‡  â”‚ çŠ¶æ€                          â”‚ â”‚
â”‚ â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ â”‚
â”‚ â”‚ å­¦æœ¯åŠ¨è¯    â”‚ 8%    â”‚ â‰¥15%  â”‚ âš ï¸ ä¸è¶³ (ç¼ºå°‘examine,argue)  â”‚ â”‚
â”‚ â”‚ å­¦æœ¯å½¢å®¹è¯  â”‚ 6%    â”‚ â‰¥10%  â”‚ âš ï¸ ä¸è¶³ (ç¼ºå°‘empirical)      â”‚ â”‚
â”‚ â”‚ å­¦æœ¯çŸ­è¯­    â”‚ 2%    â”‚ â‰¥5%   â”‚ âš ï¸ ä¸è¶³ (ç¼ºå°‘å¯¹æ¯”è¡¨è¿°)       â”‚ â”‚
â”‚ â”‚ è°¨æ…è¡¨è¿°    â”‚ 4%    â”‚ â‰¥8%   â”‚ âš ï¸ ä¸è¶³ (ç¼ºå°‘hedging)        â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                  â”‚
â”‚ å·²æ£€æµ‹åˆ°çš„äººç±»ç‰¹å¾è¯:                                            â”‚
â”‚ â€¢ åŠ¨è¯: "suggest" Ã— 2, "demonstrate" Ã— 1, "identify" Ã— 1        â”‚
â”‚ â€¢ å½¢å®¹è¯: "significant" Ã— 3, "consistent" Ã— 1                   â”‚
â”‚ â€¢ çŸ­è¯­: "results indicate" Ã— 1                                  â”‚
â”‚                                                                  â”‚
â”‚ å»ºè®®å¢åŠ çš„äººç±»ç‰¹å¾ Suggested Additions:                          â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Para 1: å»ºè®®å¢åŠ  "examine", "investigate"                   â”‚ â”‚
â”‚ â”‚ Para 3: å»ºè®®å¢åŠ  "in contrast to", "data suggest"          â”‚ â”‚
â”‚ â”‚ Para 5: å»ºè®®å¢åŠ è°¨æ…è¡¨è¿° "may", "appears to"               â”‚ â”‚
â”‚ â”‚ Para 7: å»ºè®®å¢åŠ  "empirical", "quantitative"               â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                  â”‚
â”‚ [æŸ¥çœ‹è¯¦æƒ…] [ç»§ç»­ä¸‹ä¸€æ­¥ â†’]                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Step 5.3: æ›¿æ¢å€™é€‰ç”Ÿæˆ (Replacement Candidate Generation)

**ç›®çš„ Purpose**ï¼šä¸ºæ¯ä¸ªæ£€æµ‹åˆ°çš„AIGCæŒ‡çº¹è¯ç”Ÿæˆä¸Šä¸‹æ–‡é€‚é…çš„æ›¿æ¢å€™é€‰ï¼Œä¼˜å…ˆé€‰æ‹©äººç±»ç‰¹å¾è¯æ±‡ã€‚

**ç”Ÿæˆç­–ç•¥**ï¼š
| ç­–ç•¥ Strategy | è¯´æ˜ Description | ä¼˜å…ˆçº§ Priority |
|--------------|-----------------|-----------------|
| äººç±»ç‰¹å¾è¯ä¼˜å…ˆ | ç”¨äººç±»ç‰¹å¾è¯æ›¿æ¢ | P0 |
| å£è¯­åŒ–ç­‰çº§é€‚é… | æ ¹æ®è®¾å®šç­‰çº§é€‰æ‹© | P1 |
| ä¸Šä¸‹æ–‡è¯­ä¹‰é€‚é… | è€ƒè™‘å‰åæ–‡è¯­ä¹‰ | P1 |
| å­¦æœ¯è§„èŒƒé€‚é… | ç¡®ä¿æ›¿æ¢åç¬¦åˆå­¦æœ¯è§„èŒƒ | P2 |

**æ›¿æ¢æ˜ å°„ç¤ºä¾‹**ï¼š
```python
REPLACEMENT_MAP = {
    # Type A â†’ Human feature words
    "delve": {
        "academic": ["examine", "investigate", "explore"],
        "moderate": ["study", "look at", "analyze"],
        "casual": ["look into", "check out", "dig into"]
    },
    "tapestry": {
        "academic": ["combination", "array", "synthesis"],
        "moderate": ["mix", "collection", "range"],
        "casual": ["mix", "combo", "blend"]
    },
    # Type B â†’ Simpler alternatives
    "comprehensive": {
        "academic": ["thorough", "complete", "extensive"],
        "moderate": ["full", "detailed", "complete"],
        "casual": ["full", "complete", "detailed"]
    },
    "leverage": {
        "academic": ["employ", "use", "apply"],
        "moderate": ["use", "apply", "build on"],
        "casual": ["use", "take advantage of"]
    },
    # Phrases â†’ Academic alternatives
    "plays a crucial role": {
        "academic": "is essential to",
        "moderate": "is important for",
        "casual": "matters for"
    },
    "in the realm of": {
        "academic": "within",
        "moderate": "in",
        "casual": "in"
    }
}
```

**è¾“å‡ºæ•°æ®ç»“æ„**ï¼š
```python
class ReplacementCandidateResponse(BaseModel):
    candidates: List[ReplacementCandidate]
    rule_suggestions: List[RuleSuggestion]  # Track B
    total_replaceable: int

class ReplacementCandidate(BaseModel):
    original: str
    original_type: str  # type_a, type_b, phrase
    candidates: List[CandidateOption]
    paragraph_index: int
    sentence_index: int
    context: str  # surrounding text

class CandidateOption(BaseModel):
    replacement: str
    is_human_feature: bool
    colloquialism_level: str
    confidence: float
    reason: str
    reason_zh: str
```

---

### Step 5.4: LLMæ®µè½çº§æ”¹å†™ (LLM Paragraph-Level Rewriting)

**ç›®çš„ Purpose**ï¼šæ ¸å¿ƒæ”¹å†™æ­¥éª¤ï¼ŒæŒ‰æ®µè½ä¸ºå•ä½è¿›è¡Œç»¼åˆæ”¹å†™ï¼Œæ¶ˆé™¤AIGCæŒ‡çº¹å¹¶å¢åŠ äººç±»ç‰¹å¾ã€‚

**æ”¹å†™åŸåˆ™**ï¼š
| åŸåˆ™ Principle | è¯´æ˜ Description |
|---------------|------------------|
| æ®µè½æ•´ä½“æ€§ | ä¿æŒæ®µè½å†…éƒ¨é€»è¾‘å’Œè¯­ä¹‰è¿è´¯ |
| é”å®šè¯ä¿æŠ¤ | é”å®šè¯æ±‡ä¸å¾—ä¿®æ”¹ï¼Œåœ¨Promptä¸­æ˜ç¡®æ ‡æ³¨ |
| AIGCæ¶ˆé™¤ | æ›¿æ¢æ‰€æœ‰Type Aè¯æ±‡ï¼Œé™ä½Type B/Cå¯†åº¦ |
| äººç±»ç‰¹å¾æ³¨å…¥ | åœ¨é€‚å½“ä½ç½®å¢åŠ äººç±»å­¦æœ¯å†™ä½œç‰¹å¾ |
| å­¦æœ¯ä¸¥è°¨æ€§ | ä¿æŒå­¦æœ¯å†™ä½œè§„èŒƒï¼Œé¿å…å£è¯­åŒ–è¿‡åº¦ |
| è¯­ä¹‰ä¿æŒ | æ”¹å†™åè¯­ä¹‰ç›¸ä¼¼åº¦ â‰¥ 0.85 |

**Promptè®¾è®¡**ï¼š
```python
PARAGRAPH_REWRITE_PROMPT = """
## TASK: Rewrite paragraph to reduce AI detection while maintaining academic rigor

## Original Paragraph
{paragraph_text}

## AIGC Issues Detected (MUST FIX):
{aigc_issues}

## Human Feature Injection Targets:
{human_feature_targets}

## PROTECTED TERMS (DO NOT MODIFY - these are technical terms):
{locked_terms}

## Colloquialism Level: {level}/10
{style_guide}

## CRITICAL RULES:
1. **AIGC Elimination**:
   - Replace ALL Type A words: {type_a_list}
   - Replace Type B words where possible: {type_b_list}
   - Rewrite Type C phrases: {phrase_list}

2. **Human Feature Enhancement**:
   - Inject academic verbs: examine, investigate, demonstrate, identify
   - Use hedging language: suggests, may, appears to, could potentially
   - Add academic phrases: "results indicate", "in contrast to", "data suggest"

3. **Locked Term Protection**:
   - The following terms MUST remain UNCHANGED: {locked_terms}
   - Do not replace, paraphrase, or modify these terms

4. **Academic Rigor**:
   - Maintain formal academic register (for level 0-5)
   - Preserve logical flow and argumentation
   - Keep citation formats intact
   - Use precise, specific language (avoid vague generalizations)

5. **Semantic Preservation**:
   - Maintain the EXACT same meaning
   - Do not add new claims or information
   - Do not remove important qualifications

## Response Format (JSON):
{{
  "rewritten_paragraph": "...",
  "changes": [
    {{"original": "...", "replacement": "...", "reason": "...", "reason_zh": "..."}}
  ],
  "aigc_removed": ["delve", "tapestry"],
  "human_features_added": ["examine", "suggests"],
  "locked_terms_preserved": true,
  "semantic_similarity_estimate": 0.92
}}
"""
```

**æ‰¹é‡å¤„ç†ç­–ç•¥**ï¼š
```python
async def batch_rewrite_paragraphs(
    paragraphs: List[str],
    aigc_issues_per_para: Dict[int, List],
    human_targets_per_para: Dict[int, List],
    locked_terms: List[str],
    colloquialism_level: int
) -> List[RewriteResult]:
    """
    Process paragraphs in batches to optimize LLM calls
    æŒ‰æ‰¹æ¬¡å¤„ç†æ®µè½ä»¥ä¼˜åŒ–LLMè°ƒç”¨
    """
    results = []

    # Group paragraphs by risk level for prioritization
    high_risk = [i for i, issues in aigc_issues_per_para.items()
                 if len(issues) > 3]
    medium_risk = [i for i, issues in aigc_issues_per_para.items()
                   if 1 <= len(issues) <= 3]
    low_risk = [i for i, issues in aigc_issues_per_para.items()
                if len(issues) == 0]

    # Process high-risk paragraphs with full LLM attention
    for para_idx in high_risk:
        result = await rewrite_paragraph_llm(
            paragraphs[para_idx],
            aigc_issues_per_para[para_idx],
            human_targets_per_para.get(para_idx, []),
            locked_terms,
            colloquialism_level
        )
        results.append(result)

    # Process medium-risk with hybrid approach
    for para_idx in medium_risk:
        # Try rule-based first, fallback to LLM if needed
        result = await rewrite_paragraph_hybrid(...)
        results.append(result)

    # Low-risk paragraphs: rule-based only
    for para_idx in low_risk:
        result = rewrite_paragraph_rules(...)
        results.append(result)

    return results
```

**ç”¨æˆ·ç•Œé¢è®¾è®¡**ï¼š
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 5.4: LLMæ®µè½çº§æ”¹å†™ LLM Paragraph-Level Rewriting           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ”¹å†™è¿›åº¦ Rewriting Progress:                                     â”‚
â”‚                                                                  â”‚
â”‚ [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60% (6/10 paragraphs)          â”‚
â”‚                                                                  â”‚
â”‚ å½“å‰æ®µè½ Current Paragraph (Para 3 - High Risk):                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ åŸæ–‡ Original:                                              â”‚ â”‚
â”‚ â”‚ "This study delves into the multifaceted tapestry of       â”‚ â”‚
â”‚ â”‚  machine learning, leveraging comprehensive datasets..."    â”‚ â”‚
â”‚ â”‚                                                             â”‚ â”‚
â”‚ â”‚ æ”¹å†™å Rewritten:                                           â”‚ â”‚
â”‚ â”‚ "This study examines the complex interactions within       â”‚ â”‚
â”‚ â”‚  machine learning, using extensive datasets..."            â”‚ â”‚
â”‚ â”‚                                                             â”‚ â”‚
â”‚ â”‚ å˜æ›´ Changes:                                               â”‚ â”‚
â”‚ â”‚ â€¢ "delves into" â†’ "examines" [AIGCæ¶ˆé™¤+äººç±»ç‰¹å¾]           â”‚ â”‚
â”‚ â”‚ â€¢ "multifaceted tapestry" â†’ "complex interactions" [æ¶ˆé™¤]  â”‚ â”‚
â”‚ â”‚ â€¢ "leveraging" â†’ "using" [é™ä½AIç‰¹å¾]                      â”‚ â”‚
â”‚ â”‚ â€¢ "comprehensive" â†’ "extensive" [é™ä½AIç‰¹å¾]               â”‚ â”‚
â”‚ â”‚                                                             â”‚ â”‚
â”‚ â”‚ ğŸ”’ ä¿æŠ¤è¯æ±‡å®Œå¥½: "machine learning", "datasets"            â”‚ â”‚
â”‚ â”‚ ğŸ“Š è¯­ä¹‰ç›¸ä¼¼åº¦: 94%                                          â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                  â”‚
â”‚ åŒè½¨å»ºè®® Dual-Track Suggestions:                                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ [A] LLMå»ºè®® - é£é™©: 25 | è¯­ä¹‰: 94% | äººç±»ç‰¹å¾: +3          â”‚ â”‚
â”‚ â”‚ [B] è§„åˆ™å»ºè®® - é£é™©: 35 | è¯­ä¹‰: 98% | äººç±»ç‰¹å¾: +1          â”‚ â”‚
â”‚ â”‚ [C] è‡ªå®šä¹‰ ___________________________________________      â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                  â”‚
â”‚ [æ¥å—A] [æ¥å—B] [æ‰‹åŠ¨ä¿®æ”¹] [è·³è¿‡] [ä¸‹ä¸€æ®µ â†’]                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Step 5.5: æ”¹å†™ç»“æœéªŒè¯ (Rewrite Result Validation)

**ç›®çš„ Purpose**ï¼šéªŒè¯æ”¹å†™ç»“æœçš„è´¨é‡ï¼Œç¡®ä¿è¯­ä¹‰ä¿æŒã€AIGCé£é™©é™ä½ã€äººç±»ç‰¹å¾æå‡ã€å­¦æœ¯è§„èŒƒç¬¦åˆã€‚

**éªŒè¯ç»´åº¦**ï¼š
| ç»´åº¦ Dimension | é˜ˆå€¼ Threshold | éªŒè¯æ–¹æ³• Method |
|---------------|---------------|-----------------|
| è¯­ä¹‰ç›¸ä¼¼åº¦ | â‰¥ 0.85 | Sentence-BERT |
| AIGCé£é™©é™ä½ | é™ä½ â‰¥ 30% | é‡æ–°æ£€æµ‹ |
| äººç±»ç‰¹å¾æå‡ | æå‡ â‰¥ 10% | é‡æ–°åˆ†æ |
| é”å®šè¯å®Œæ•´ | 100% | ç²¾ç¡®åŒ¹é… |
| å­¦æœ¯è§„èŒƒ | é€šè¿‡ | è§„åˆ™æ£€æŸ¥ |

**å­¦æœ¯è§„èŒƒæ£€æŸ¥é¡¹**ï¼š
```python
ACADEMIC_NORM_CHECKS = {
    "no_contractions": {
        "pattern": r"\b(don't|won't|can't|isn't|aren't|wasn't|weren't)\b",
        "level_threshold": 5,  # Only check for level 0-5
        "message": "Academic writing should avoid contractions"
    },
    "no_first_person": {
        "pattern": r"\b(I|we|my|our|us|me)\b",
        "level_threshold": 5,
        "message": "Academic writing should avoid first-person pronouns"
    },
    "no_informal_language": {
        "pattern": r"\b(kind of|sort of|basically|actually|really|pretty much)\b",
        "level_threshold": 6,
        "message": "Academic writing should avoid informal language"
    },
    "citation_preserved": {
        "check": "citation_format_unchanged",
        "message": "Citations must remain in original format"
    }
}
```

**è¾“å‡ºæ•°æ®ç»“æ„**ï¼š
```python
class ValidationResponse(BaseModel):
    overall_pass: bool
    semantic_similarity: float
    aigc_risk_before: int
    aigc_risk_after: int
    risk_reduction: float
    human_feature_before: int
    human_feature_after: int
    feature_improvement: float
    locked_terms_preserved: bool
    academic_norm_violations: List[NormViolation]
    final_paragraphs: List[ValidatedParagraph]
    quality_report: QualityReport

class ValidatedParagraph(BaseModel):
    index: int
    original: str
    rewritten: str
    accepted: bool
    validation_scores: Dict[str, float]
    issues: List[str]

class QualityReport(BaseModel):
    total_paragraphs: int
    paragraphs_improved: int
    paragraphs_unchanged: int
    paragraphs_failed: int
    overall_quality_score: int
    recommendations: List[str]
```

**ç”¨æˆ·ç•Œé¢è®¾è®¡**ï¼š
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 5.5: æ”¹å†™ç»“æœéªŒè¯ Rewrite Result Validation                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ•´ä½“éªŒè¯ç»“æœ Overall Validation: âœ… é€šè¿‡                         â”‚
â”‚                                                                  â”‚
â”‚ è´¨é‡æŒ‡æ ‡ Quality Metrics:                                        â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ æŒ‡æ ‡              â”‚ æ”¹å†™å‰ â”‚ æ”¹å†™å â”‚ å˜åŒ–   â”‚ çŠ¶æ€          â”‚ â”‚
â”‚ â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ â”‚
â”‚ â”‚ AIGCé£é™©åˆ†æ•°      â”‚ 72     â”‚ 28     â”‚ -61%   â”‚ âœ… å¤§å¹…é™ä½   â”‚ â”‚
â”‚ â”‚ äººç±»ç‰¹å¾å¾—åˆ†      â”‚ 38     â”‚ 65     â”‚ +71%   â”‚ âœ… æ˜¾è‘—æå‡   â”‚ â”‚
â”‚ â”‚ å¹³å‡è¯­ä¹‰ç›¸ä¼¼åº¦    â”‚ -      â”‚ 91%    â”‚ -      â”‚ âœ… â‰¥85%      â”‚ â”‚
â”‚ â”‚ é”å®šè¯æ±‡å®Œæ•´æ€§    â”‚ -      â”‚ 100%   â”‚ -      â”‚ âœ… å…¨éƒ¨ä¿ç•™   â”‚ â”‚
â”‚ â”‚ å­¦æœ¯è§„èŒƒç¬¦åˆ      â”‚ -      â”‚ 98%    â”‚ -      â”‚ âœ… é€šè¿‡       â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                  â”‚
â”‚ æ®µè½éªŒè¯è¯¦æƒ… Paragraph Validation Details:                       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Para 1: âœ… é€šè¿‡ (è¯­ä¹‰:93%, é£é™©:72â†’25, äººç±»:+15)           â”‚ â”‚
â”‚ â”‚ Para 2: âœ… é€šè¿‡ (è¯­ä¹‰:95%, é£é™©:45â†’20, äººç±»:+8)            â”‚ â”‚
â”‚ â”‚ Para 3: âœ… é€šè¿‡ (è¯­ä¹‰:89%, é£é™©:85â†’30, äººç±»:+22)           â”‚ â”‚
â”‚ â”‚ Para 4: âš ï¸ è­¦å‘Š (è¯­ä¹‰:84%, æ¥è¿‘é˜ˆå€¼)                       â”‚ â”‚
â”‚ â”‚ Para 5: âœ… é€šè¿‡ (è¯­ä¹‰:92%, é£é™©:60â†’28, äººç±»:+12)           â”‚ â”‚
â”‚ â”‚ ...                                                         â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                  â”‚
â”‚ å­¦æœ¯è§„èŒƒé—®é¢˜ Academic Norm Issues (1):                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Para 4: æ£€æµ‹åˆ°ç¼©å†™ "don't" â†’ å»ºè®®æ”¹ä¸º "do not"             â”‚ â”‚
â”‚ â”‚         [è‡ªåŠ¨ä¿®å¤] [å¿½ç•¥]                                   â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                  â”‚
â”‚ [å¯¼å‡ºæŠ¥å‘Š] [è¿”å›ä¿®æ”¹] [ç¡®è®¤å®Œæˆ âœ“]                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## äº”ã€APIè®¾è®¡ | API Design

### 5.1 ç«¯ç‚¹è®¾è®¡ | Endpoint Design

```python
# Step 5.0: Prepare context
@router.post("/api/v1/analysis/layer1/context")
async def prepare_lexical_context(
    request: LexicalContextRequest
) -> LexicalContextResponse:
    """Prepare lexical analysis context"""
    pass

# Step 5.1: Fingerprint detection
@router.post("/api/v1/analysis/layer1/fingerprint")
async def detect_fingerprints(
    request: FingerprintDetectionRequest
) -> FingerprintDetectionResponse:
    """Detect AIGC fingerprint words and phrases"""
    pass

# Step 5.2: Human feature analysis
@router.post("/api/v1/analysis/layer1/human-features")
async def analyze_human_features(
    request: HumanFeatureAnalysisRequest
) -> HumanFeatureAnalysisResponse:
    """Analyze human academic writing feature coverage"""
    pass

# Step 5.3: Generate replacement candidates
@router.post("/api/v1/analysis/layer1/candidates")
async def generate_replacement_candidates(
    request: ReplacementCandidateRequest
) -> ReplacementCandidateResponse:
    """Generate replacement candidates for fingerprint words"""
    pass

# Step 5.4: LLM paragraph rewriting
@router.post("/api/v1/analysis/layer1/rewrite")
async def rewrite_paragraphs(
    request: ParagraphRewriteRequest
) -> ParagraphRewriteResponse:
    """Rewrite paragraphs to reduce AIGC and enhance human features"""
    pass

# Step 5.5: Validate results
@router.post("/api/v1/analysis/layer1/validate")
async def validate_results(
    request: ValidationRequest
) -> ValidationResponse:
    """Validate rewrite results"""
    pass

# Combined endpoint for full Layer 1 processing
@router.post("/api/v1/analysis/layer1/full")
async def process_layer1_full(
    request: Layer1FullRequest
) -> Layer1FullResponse:
    """Run complete Layer 1 analysis and rewriting pipeline"""
    pass
```

### 5.2 æ•°æ®æµè®¾è®¡ | Data Flow Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Layer 1 Data Flow                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  Input from Layer 2                                                  â”‚
â”‚  â”œâ”€â”€ sentences[]                                                     â”‚
â”‚  â”œâ”€â”€ sentence_contexts[]                                             â”‚
â”‚  â”œâ”€â”€ paragraph_sentence_map{}                                        â”‚
â”‚  â””â”€â”€ locked_terms[] (from Step 1.0)                                 â”‚
â”‚                                                                      â”‚
â”‚        â†“ Step 5.0                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚ paragraph_term_map{}     â”‚ â† Build word-paragraph mapping        â”‚
â”‚  â”‚ feature_db               â”‚ â† Load AIGC/Human feature DB          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚                                                                      â”‚
â”‚        â†“ Step 5.1                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚ fingerprint_issues[]     â”‚ â† Detected AIGC fingerprints          â”‚
â”‚  â”‚ density_per_para{}       â”‚ â† Per-paragraph density               â”‚
â”‚  â”‚ risk_score               â”‚ â† Overall risk score                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚                                                                      â”‚
â”‚        â†“ Step 5.2                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚ human_coverage{}         â”‚ â† Human feature coverage              â”‚
â”‚  â”‚ injection_points[]       â”‚ â† Where to add human features         â”‚
â”‚  â”‚ feature_gaps[]           â”‚ â† What features are missing           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚                                                                      â”‚
â”‚        â†“ Step 5.3                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚ replacement_candidates{} â”‚ â† Candidates per fingerprint          â”‚
â”‚  â”‚ rule_suggestions[]       â”‚ â† Track B suggestions                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚                                                                      â”‚
â”‚        â†“ Step 5.4                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚ rewritten_paragraphs[]   â”‚ â† LLM rewritten text                  â”‚
â”‚  â”‚ llm_suggestions[]        â”‚ â† Track A suggestions                 â”‚
â”‚  â”‚ changes[]                â”‚ â† Detailed change log                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚                                                                      â”‚
â”‚        â†“ Step 5.5                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚ validation_results{}     â”‚ â† Validation scores                   â”‚
â”‚  â”‚ final_paragraphs[]       â”‚ â† Validated final text                â”‚
â”‚  â”‚ quality_report           â”‚ â† Overall quality assessment          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚                                                                      â”‚
â”‚  Output                                                              â”‚
â”‚  â”œâ”€â”€ final_document_text                                            â”‚
â”‚  â”œâ”€â”€ analysis_report                                                â”‚
â”‚  â””â”€â”€ change_log[]                                                   â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## å…­ã€ä¸ç°æœ‰ç³»ç»Ÿé›†æˆ | Integration with Existing System

### 6.1 ä¸ LexicalOrchestrator çš„å…³ç³»

ç°æœ‰çš„ `lexical_orchestrator.py` å®ç°äº†åŸºç¡€çš„æŒ‡çº¹æ£€æµ‹å’Œè¿æ¥è¯åˆ†æã€‚æ–°è®¾è®¡å°†ï¼š

1. **ä¿ç•™ç°æœ‰æ£€æµ‹é€»è¾‘** - Step 5.1 å¤ç”¨ `FINGERPRINT_TYPE_A/B/C` è¯å…¸
2. **å¢å¼ºæ£€æµ‹èƒ½åŠ›** - æ·»åŠ äººç±»ç‰¹å¾åˆ†æï¼ˆStep 5.2ï¼‰
3. **æ·»åŠ æ”¹å†™èƒ½åŠ›** - æ•´åˆ `llm_track.py` å’Œ `rule_track.py`ï¼ˆStep 5.4ï¼‰
4. **æ·»åŠ éªŒè¯æœºåˆ¶** - æ–°å¢éªŒè¯æ­¥éª¤ï¼ˆStep 5.5ï¼‰

### 6.2 ä¸åŒè½¨ç³»ç»Ÿçš„å…³ç³»

| ç»„ä»¶ Component | é›†æˆæ–¹å¼ Integration |
|----------------|---------------------|
| `llm_track.py` | Step 5.4 ä½¿ç”¨ LLMTrack ç”Ÿæˆå»ºè®® |
| `rule_track.py` | Step 5.3/5.4 ä½¿ç”¨ RuleTrack ç”Ÿæˆå€™é€‰ |
| é”å®šè¯æ±‡ | ä» `get_locked_terms_from_session()` è·å– |

### 6.3 ä»£ç ç»“æ„å»ºè®®

```
src/core/analyzer/layers/
â”œâ”€â”€ lexical_orchestrator.py     # é‡æ„ä»¥æ”¯æŒå­æ­¥éª¤
â”œâ”€â”€ lexical/                    # NEW: å­æ­¥éª¤æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ context_preparation.py  # Step 5.0
â”‚   â”œâ”€â”€ fingerprint_detector.py # Step 5.1 (å¢å¼º)
â”‚   â”œâ”€â”€ human_feature_analyzer.py # Step 5.2 (NEW)
â”‚   â”œâ”€â”€ candidate_generator.py  # Step 5.3 (NEW)
â”‚   â”œâ”€â”€ paragraph_rewriter.py   # Step 5.4 (NEW)
â”‚   â””â”€â”€ result_validator.py     # Step 5.5 (NEW)

src/api/routes/analysis/
â”œâ”€â”€ lexical.py                  # ç°æœ‰è·¯ç”±å¢å¼º
â”œâ”€â”€ lexical/                    # NEW: å­æ­¥éª¤ç«¯ç‚¹
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ context.py              # Step 5.0 API
â”‚   â”œâ”€â”€ fingerprint.py          # Step 5.1 API
â”‚   â”œâ”€â”€ human_features.py       # Step 5.2 API
â”‚   â”œâ”€â”€ candidates.py           # Step 5.3 API
â”‚   â”œâ”€â”€ rewrite.py              # Step 5.4 API
â”‚   â””â”€â”€ validate.py             # Step 5.5 API

src/data/
â”œâ”€â”€ aigc_fingerprints.json      # AIGCæŒ‡çº¹è¯åº“
â”œâ”€â”€ human_features.json         # äººç±»ç‰¹å¾è¯åº“ (NEW)
â””â”€â”€ replacement_map.json        # æ›¿æ¢æ˜ å°„è¡¨
```

---

## ä¸ƒã€å®ç°ä¼˜å…ˆçº§ | Implementation Priority

| ä¼˜å…ˆçº§ Priority | å­æ­¥éª¤ Sub-Step | åŸå›  Reason |
|----------------|----------------|-------------|
| **P0** | Step 5.0 è¯æ±‡ç¯å¢ƒå‡†å¤‡ | åŸºç¡€æ­¥éª¤ï¼Œæ‰€æœ‰åç»­æ­¥éª¤ä¾èµ– |
| **P0** | Step 5.1 AIGCæŒ‡çº¹æ£€æµ‹ | æ ¸å¿ƒæ£€æµ‹ï¼Œå·²æœ‰åŸºç¡€å®ç° |
| **P1** | Step 5.4 LLMæ®µè½çº§æ”¹å†™ | æ ¸å¿ƒæ”¹å†™åŠŸèƒ½ï¼Œç”¨æˆ·æ„ŸçŸ¥æœ€å¼º |
| **P1** | Step 5.5 æ”¹å†™ç»“æœéªŒè¯ | è´¨é‡ä¿éšœï¼Œå¿…é¡»ä¸æ”¹å†™åŒæ­¥ |
| **P2** | Step 5.2 äººç±»ç‰¹å¾åˆ†æ | å¢å¼ºåŠŸèƒ½ï¼Œæå‡æ”¹å†™è´¨é‡ |
| **P2** | Step 5.3 æ›¿æ¢å€™é€‰ç”Ÿæˆ | æ”¯æŒåŒè½¨å»ºè®®ï¼Œå¯æ¸è¿›å®ç° |

---

## å…«ã€ä¸å…¶ä»–Layerè®¾è®¡çš„å¯¹æ¯” | Comparison with Other Layers

| ç‰¹ç‚¹ Feature | Layer 2 (å¥å­) | Layer 1 (è¯æ±‡) |
|-------------|---------------|---------------|
| **åˆ†æå•å…ƒ** | å¥å­åœ¨æ®µè½ä¸­ | è¯æ±‡åœ¨æ®µè½ä¸­ |
| **ä¸Šä¸‹æ–‡** | æ®µè½ä¸Šä¸‹æ–‡ | å¥å­+æ®µè½ä¸Šä¸‹æ–‡ |
| **ä¸»è¦æ“ä½œ** | åˆå¹¶/æ‹†åˆ†/è°ƒæ•´å¥å­ | æ›¿æ¢/æ”¹å†™è¯æ±‡ |
| **LLMä½¿ç”¨** | å¥å¼å¤šæ ·åŒ– | æ®µè½çº§ç»¼åˆæ”¹å†™ |
| **è§„åˆ™ä½¿ç”¨** | å¥æ³•é‡ç»„è§„åˆ™ | è¯æ±‡æ›¿æ¢è§„åˆ™ |
| **äººç±»ç‰¹å¾** | å¥å¼å¤šæ ·æ€§ | è¯æ±‡è¦†ç›–ç‡ |
| **ç”¨æˆ·äº¤äº’** | ç¡®è®¤å¥å¼å˜åŒ– | ç¡®è®¤è¯æ±‡æ›¿æ¢ |

---

## ä¹ã€æ€»ç»“ | Summary

Layer 1 (è¯æ±‡å±‚) å­æ­¥éª¤ç³»ç»Ÿè®¾è®¡çš„æ ¸å¿ƒç‰¹ç‚¹ï¼š

1. **å…ˆåˆ†æåæ”¹å†™** - Step 5.1-5.2 å…¨é¢åˆ†æé—®é¢˜ï¼ŒStep 5.4 é’ˆå¯¹æ€§æ”¹å†™
2. **æ®µè½ä¸ºå•ä½** - æŒ‰æ®µè½ç»Ÿè®¡ã€åˆ†æã€æ”¹å†™ï¼Œä¿æŒä¸Šä¸‹æ–‡è¿è´¯
3. **é”å®šè¯ä¿æŠ¤** - å…¨æµç¨‹ä¿æŠ¤ç”¨æˆ·é”å®šçš„ä¸“ä¸šæœ¯è¯­
4. **åŒå‘ä¼˜åŒ–** - åŒæ—¶æ¶ˆé™¤AIGCæŒ‡çº¹å’Œå¢åŠ äººç±»ç‰¹å¾
5. **åŒè½¨å»ºè®®** - ç»“åˆLLMæ™ºèƒ½æ”¹å†™å’Œè§„åˆ™ç¡®å®šæ€§æ›¿æ¢
6. **å­¦æœ¯ä¸¥è°¨** - éªŒè¯ç¯èŠ‚ç¡®ä¿å­¦æœ¯å†™ä½œè§„èŒƒ
7. **è´¨é‡éªŒè¯** - å¤šç»´åº¦éªŒè¯ç¡®ä¿æ”¹å†™è´¨é‡

**è¯¦ç»†è®¾è®¡è¯·å‚è€ƒæœ¬æ–‡æ¡£å„ç« èŠ‚ For detailed design, see each section of this document**
