# Sub-Step Prompt System Design
# å­æ­¥éª¤Promptç³»ç»Ÿè®¾è®¡

> Created: 2026-01-09
> Purpose: Design LLM analysis and rewriting prompts for all substeps
> ç›®çš„ï¼šä¸ºæ‰€æœ‰å­æ­¥éª¤è®¾è®¡LLMåˆ†æå’Œæ”¹å†™prompt

---

## ä¸€ã€æ—§ä»£ç å·¥ä½œæµç¨‹æ€»ç»“ | Old Code Workflow Summary

### 1.1 å®Œæ•´æµç¨‹ | Complete Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Old Code Workflow (structure analysis as example)              â”‚
â”‚  æ—§ä»£ç å·¥ä½œæµç¨‹ï¼ˆä»¥ç»“æ„åˆ†æä¸ºä¾‹ï¼‰                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Step 1: LLM Analysis åˆ†æé˜¶æ®µ                                    â”‚
â”‚  â”œâ”€â”€ POST /api/v1/structure/document/step1-1                    â”‚
â”‚  â”œâ”€â”€ Call SmartStructureAnalyzer.analyze_structure()            â”‚
â”‚  â”œâ”€â”€ LLMè¿”å›ç»“æ„åŒ–JSON:                                          â”‚
â”‚  â”‚   {                                                           â”‚
â”‚  â”‚     "issues": [                                               â”‚
â”‚  â”‚       {                                                       â”‚
â”‚  â”‚         "type": "linear_flow",                                â”‚
â”‚  â”‚         "description": "...",                                 â”‚
â”‚  â”‚         "description_zh": "...",                              â”‚
â”‚  â”‚         "severity": "high",                                   â”‚
â”‚  â”‚         "affected_positions": ["1(1)", "1(2)"]                â”‚
â”‚  â”‚       }                                                       â”‚
â”‚  â”‚     ]                                                         â”‚
â”‚  â”‚   }                                                           â”‚
â”‚  â””â”€â”€ ç¼“å­˜åˆ†æç»“æœåˆ° document.structure_analysis_cache            â”‚
â”‚                                                                  â”‚
â”‚  Step 2: Display Issues å±•ç¤ºé—®é¢˜                                 â”‚
â”‚  â”œâ”€â”€ å‰ç«¯å±•ç¤ºé—®é¢˜åˆ—è¡¨                                            â”‚
â”‚  â”œâ”€â”€ ç”¨æˆ·ç‚¹å‡»é—®é¢˜ï¼Œå±•å¼€è¯¦ç»†è¯´æ˜                                  â”‚
â”‚  â””â”€â”€ ç”¨æˆ·å¤šé€‰é—®é¢˜                                                â”‚
â”‚                                                                  â”‚
â”‚  Step 3A: Generate Prompt ç”ŸæˆPromptï¼ˆå¯é€‰ï¼‰                     â”‚
â”‚  â”œâ”€â”€ POST /api/v1/structure/merge-modify/prompt                 â”‚
â”‚  â”œâ”€â”€ è¾“å…¥: {                                                     â”‚
â”‚  â”‚     selected_issues: [...],                                  â”‚
â”‚  â”‚     user_notes: "..."                                        â”‚
â”‚  â”‚   }                                                           â”‚
â”‚  â”œâ”€â”€ LLMç”Ÿæˆä¸€ä¸ªç»™ç”¨æˆ·å¤åˆ¶çš„prompt                               â”‚
â”‚  â””â”€â”€ è¿”å›: { prompt: "...", prompt_zh: "..." }                  â”‚
â”‚                                                                  â”‚
â”‚  Step 3B: AI Modify ç›´æ¥AIä¿®æ”¹ï¼ˆå¯é€‰ï¼‰                           â”‚
â”‚  â”œâ”€â”€ POST /api/v1/structure/merge-modify/apply                  â”‚
â”‚  â”œâ”€â”€ è¾“å…¥: {                                                     â”‚
â”‚  â”‚     selected_issues: [...],                                  â”‚
â”‚  â”‚     user_notes: "..."                                        â”‚
â”‚  â”‚   }                                                           â”‚
â”‚  â”œâ”€â”€ LLMç›´æ¥ä¿®æ”¹æ–‡æ¡£                                             â”‚
â”‚  â””â”€â”€ è¿”å›: { modified_text: "...", changes_summary_zh: "..." }  â”‚
â”‚                                                                  â”‚
â”‚  Step 4: Upload New Document or Accept ä¸Šä¼ æ–°æ–‡æ¡£æˆ–æ¥å—          â”‚
â”‚  â”œâ”€â”€ ç”¨æˆ·å¯ä»¥ä¸Šä¼ æ–°çš„docx/txtæ–‡ä»¶                                â”‚
â”‚  â””â”€â”€ æˆ–è€…æ¥å—AIä¿®æ”¹çš„ç»“æœ                                        â”‚
â”‚                                                                  â”‚
â”‚  Step 5: Pass to Next Substep ä¼ é€’ç»™ä¸‹ä¸€ä¸ªsubstep                â”‚
â”‚  â””â”€â”€ ä¸‹ä¸€ä¸ªsubstepåŸºäºä¿®æ”¹åçš„æ–‡æœ¬è¿›è¡Œåˆ†æ                        â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 å…³é”®Schema | Key Schemas

```python
# é€‰ä¸­çš„é—®é¢˜ | Selected Issue
class SelectedIssue(BaseModel):
    type: str  # é—®é¢˜ç±»å‹
    description: str  # è‹±æ–‡æè¿°
    description_zh: str  # ä¸­æ–‡æè¿°
    severity: str  # high/medium/low
    affected_positions: List[str]  # å—å½±å“ä½ç½®

# åˆå¹¶ä¿®æ”¹è¯·æ±‚ | Merge Modify Request
class MergeModifyRequest(BaseModel):
    document_id: str
    session_id: Optional[str]
    selected_issues: List[SelectedIssue]
    user_notes: Optional[str]  # ç”¨æˆ·çš„é¢å¤–æŒ‡å¯¼æ„è§
    mode: str  # "prompt" or "apply"

# ç”ŸæˆPromptå“åº” | Generate Prompt Response
class MergeModifyPromptResponse(BaseModel):
    prompt: str  # ç”Ÿæˆçš„promptä¾›ç”¨æˆ·å¤åˆ¶
    prompt_zh: str  # ä¸­æ–‡æç¤ºè¯æè¿°
    issues_summary_zh: str
    colloquialism_level: int
    estimated_changes: int

# AIä¿®æ”¹å“åº” | AI Modify Response
class MergeModifyApplyResponse(BaseModel):
    modified_text: str  # ä¿®æ”¹åçš„æ–‡æ¡£
    changes_summary_zh: str  # ä¿®æ”¹æ€»ç»“
    changes_count: int
    issues_addressed: List[str]
    remaining_attempts: int
```

---

## äºŒã€é€šç”¨Substepå·¥ä½œæµç¨‹ | Generic Substep Workflow

### 2.1 æ¯ä¸ªSubstepçš„æ ‡å‡†æµç¨‹ | Standard Flow for Each Substep

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Generic Substep Workflow                                        â”‚
â”‚  é€šç”¨Substepå·¥ä½œæµç¨‹                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Phase 1: Analysis åˆ†æé˜¶æ®µ                                       â”‚
â”‚  â”œâ”€â”€ POST /api/v1/layer{X}/step{Y}-{Z}/analyze                  â”‚
â”‚  â”œâ”€â”€ æ¥æ”¶: { text, session_id, locked_terms }                   â”‚
â”‚  â”œâ”€â”€ è°ƒç”¨LLM: ANALYSIS_PROMPTï¼ˆåªåˆ†æå½“å‰æ­¥éª¤çš„é—®é¢˜ï¼‰            â”‚
â”‚  â””â”€â”€ è¿”å›: { issues: [...], risk_score, recommendations }       â”‚
â”‚      âš ï¸ IMPORTANT: issuesæ•°ç»„åŒ…å«æ‰€æœ‰è¯¦ç»†ä¿¡æ¯ï¼Œä¾›å±•å¼€æ—¶ä½¿ç”¨      â”‚
â”‚                                                                  â”‚
â”‚  Phase 2: User Selection ç”¨æˆ·é€‰æ‹©é˜¶æ®µ                            â”‚
â”‚  â”œâ”€â”€ å‰ç«¯å±•ç¤ºé—®é¢˜åˆ—è¡¨ï¼ˆæŠ˜å çŠ¶æ€ï¼‰                                â”‚
â”‚  â”œâ”€â”€ ç”¨æˆ·ç‚¹å‡»å±•å¼€ â†’ å‰ç«¯ç›´æ¥æ˜¾ç¤ºç¼“å­˜çš„è¯¦ç»†ä¿¡æ¯ï¼ˆæ— éœ€å†æ¬¡è°ƒç”¨ï¼‰   â”‚
â”‚  â””â”€â”€ ç”¨æˆ·å¤šé€‰é—®é¢˜ + å¯é€‰è¾“å…¥user_notes                           â”‚
â”‚                                                                  â”‚
â”‚  Phase 3A: Generate Rewrite Prompt ç”Ÿæˆæ”¹å†™Prompt               â”‚
â”‚  â”œâ”€â”€ POST /api/v1/layer{X}/step{Y}-{Z}/merge-modify/prompt      â”‚
â”‚  â”œâ”€â”€ æ¥æ”¶: { selected_issues, user_notes, locked_terms }        â”‚
â”‚  â”œâ”€â”€ è°ƒç”¨LLM: REWRITE_PROMPT_GENERATION                         â”‚
â”‚  â””â”€â”€ è¿”å›: { prompt, prompt_zh, estimated_changes }             â”‚
â”‚                                                                  â”‚
â”‚  Phase 3B: Direct AI Modification AIç›´æ¥ä¿®æ”¹                     â”‚
â”‚  â”œâ”€â”€ POST /api/v1/layer{X}/step{Y}-{Z}/merge-modify/apply       â”‚
â”‚  â”œâ”€â”€ æ¥æ”¶: { selected_issues, user_notes, locked_terms }        â”‚
â”‚  â”œâ”€â”€ è°ƒç”¨LLM: REWRITE_APPLYï¼ˆåŸºäºé€‰ä¸­é—®é¢˜+ç”¨æˆ·æŒ‡å¯¼ä¿®æ”¹æ–‡æ¡£ï¼‰     â”‚
â”‚  â””â”€â”€ è¿”å›: { modified_text, changes_summary, issues_addressed } â”‚
â”‚                                                                  â”‚
â”‚  Phase 4: Accept Modified Text æ¥å—ä¿®æ”¹åæ–‡æœ¬                    â”‚
â”‚  â””â”€â”€ ä¼ é€’ç»™ä¸‹ä¸€ä¸ªsubstep: next_substep(modified_text)           â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 ä¸¤ç±»Prompt | Two Types of Prompts

æ¯ä¸ªsubstepéœ€è¦2ç§promptï¼š

1. **ANALYSIS_PROMPTï¼ˆåˆ†æpromptï¼‰**
   - ç›®çš„ï¼šåªåˆ†æå½“å‰æ­¥éª¤çš„ç‰¹å®šé—®é¢˜
   - è¾“å…¥ï¼šæ–‡æ¡£æ–‡æœ¬
   - è¾“å‡ºï¼šç»“æ„åŒ–JSONé—®é¢˜åˆ—è¡¨
   - âš ï¸ **å…³é”®**ï¼šæ¯ä¸ªissueå¿…é¡»åŒ…å«å®Œæ•´çš„è¯¦ç»†ä¿¡æ¯ï¼Œå› ä¸ºå‰ç«¯å±•å¼€æ—¶ä¸ä¼šå†æ¬¡è°ƒç”¨LLM

2. **REWRITE_PROMPTï¼ˆæ”¹å†™promptï¼‰**
   - ç›®çš„ï¼šåŸºäºç”¨æˆ·é€‰ä¸­çš„é—®é¢˜å’ŒæŒ‡å¯¼æ„è§ä¿®æ”¹æ–‡æ¡£
   - è¾“å…¥ï¼šåŸæ–‡æ¡£ + selected_issues + user_notes + locked_terms
   - è¾“å‡ºï¼šä¿®æ”¹åçš„æ–‡æ¡£ + ä¿®æ”¹è¯´æ˜

### 2.3 Issueå¯¹è±¡çš„æ ‡å‡†ç»“æ„ | Standard Issue Object Structure

æ¯ä¸ªissueå¿…é¡»åŒ…å«ä»¥ä¸‹å­—æ®µï¼ˆç¬¬ä¸€æ¬¡åˆ†ææ—¶å…¨éƒ¨è¿”å›ï¼‰ï¼š

```json
{
  "type": "issue_type_identifier",
  "description": "Brief 1-sentence description",
  "description_zh": "ç®€çŸ­1å¥è¯æè¿°",
  "severity": "high|medium|low",
  "affected_positions": ["positions"],
  "evidence": "Specific text excerpts (2-3 examples)",

  // ğŸ‘‡ å±•å¼€æ—¶æ˜¾ç¤ºçš„è¯¦ç»†ä¿¡æ¯ï¼ˆç¬¬ä¸€æ¬¡åˆ†ææ—¶è¿”å›ï¼‰
  "detailed_explanation": "Why this is AI-like and how it differs from human writing (2-3 sentences)",
  "detailed_explanation_zh": "ä¸ºä»€ä¹ˆè¿™æ˜¯AIæ¨¡å¼ä»¥åŠä¸äººç±»å†™ä½œçš„åŒºåˆ«ï¼ˆ2-3å¥ï¼‰",
  "fix_suggestions": [
    "Actionable suggestion 1",
    "Actionable suggestion 2"
  ],
  "fix_suggestions_zh": [
    "å¯æ“ä½œå»ºè®®1",
    "å¯æ“ä½œå»ºè®®2"
  ]
}
```

**å‰ç«¯UXæµç¨‹**ï¼š
1. åˆå§‹æ˜¾ç¤ºï¼š`description`ã€`severity`ã€`affected_positions`
2. ç”¨æˆ·ç‚¹å‡»"å±•å¼€è¯¦æƒ…"ï¼šæ˜¾ç¤º `evidence`ã€`detailed_explanation`ã€`fix_suggestions`
3. **ä¸éœ€è¦å†æ¬¡è°ƒç”¨API**

---

## ä¸‰ã€å„Layer Substepçš„Promptè®¾è®¡ | Prompt Design for Each Substep

### Layer 5 (Document Level) - æ–‡æ¡£çº§

#### Step 1.0: Term Locking è¯æ±‡é”å®š

**å·²å®ç°** âœ… - ä½¿ç”¨ `TermExtractor.EXTRACTION_PROMPT`

#### Step 1.1: Structure Framework Detection ç»“æ„æ¡†æ¶æ£€æµ‹

**ANALYSIS_PROMPT:**
```
You are an academic document structure analyzer. Analyze the GLOBAL STRUCTURAL PATTERNS only.

## DOCUMENT TEXT:
{document_text}

## YOUR TASKS:

1. **Detect Linear Flow Pattern (çº¿æ€§æµåŠ¨)**
   - Look for "First...Second...Third" or "Initially...Subsequently...Finally" enumeration
   - Check if sections progress in a formulaic, step-by-step manner
   - AI-like: Predictable sequential progression
   - Human-like: Non-linear, withå›æº¯, jumps, or conditional logic

2. **Detect Repetitive Pattern (é‡å¤æ¨¡å¼)**
   - Check if multiple sections have identical structures
   - Example: All sections follow "Problem â†’ Analysis â†’ Solution" pattern
   - AI-like: Copy-paste section structure
   - Human-like: Varied section approaches based on content needs

3. **Detect Uniform Length (å‡åŒ€é•¿åº¦)**
   - Calculate coefficient of variation (CV) of paragraph word counts
   - AI-like: CV < 0.30 (all paragraphs similar length)
   - Human-like: CV â‰¥ 0.40 (varied paragraph lengths)

4. **Detect Predictable Order (å¯é¢„æµ‹é¡ºåº)**
   - Check if sections follow formulaic academic order
   - AI-like: Perfect Intro â†’ Literature â†’ Method â†’ Results â†’ Discussion â†’ Conclusion
   - Human-like: Some sections merged, reordered, or unconventional structure

5. **Detect Symmetry (å¯¹ç§°ç»“æ„)**
   - Check if all sections have equal number of paragraphs
   - AI-like: All sections have exactly 3-4 paragraphs
   - Human-like: Asymmetric distribution based on content importance

## LOCKED TERMS:
{locked_terms}
Preserve these terms exactly as they appear. Do NOT modify them.

## OUTPUT FORMAT (JSON only):
{{
  "issues": [
    {{
      "type": "linear_flow|repetitive_pattern|uniform_length|predictable_order|symmetry",
      "description": "English description of the specific issue found",
      "description_zh": "ä¸­æ–‡é—®é¢˜æè¿°",
      "severity": "high|medium|low",
      "affected_positions": ["section numbers or paragraph positions"],
      "evidence": "Brief evidence showing the pattern"
    }}
  ],
  "risk_score": 0-100,
  "risk_level": "high|medium|low",
  "recommendations": ["English recommendations"],
  "recommendations_zh": ["ä¸­æ–‡å»ºè®®"]
}}
```

**REWRITE_PROMPT:**
```
You are an academic document restructuring expert. Apply the following modifications to DISRUPT AI-like structural patterns while PRESERVING content quality and locked terms.

## ORIGINAL DOCUMENT:
{document_text}

## SELECTED ISSUES TO FIX:
{selected_issues}

## USER'S ADDITIONAL GUIDANCE:
{user_notes}

## LOCKED TERMS (MUST PRESERVE):
{locked_terms}
These terms must appear EXACTLY as shown. Do NOT modify, rephrase, or translate them.

## MODIFICATION STRATEGIES:

**For Linear Flow:**
- Break "First...Second...Third" progression
- Introduce non-sequential logic (e.g., discuss outlier first, then general case)
- Add conditional transitions ("In certain contexts...", "However, when...")

**For Repetitive Pattern:**
- Vary section structures (some sections detailed, some concise)
- Use different organizational approaches per section

**For Uniform Length:**
- Create intentional length asymmetry
- Expand critical sections, compress routine content
- Target CV â‰¥ 0.40

**For Predictable Order:**
- Merge or reorder sections if logical
- Example: Combine Literature + Methodology, or present Results before Method rationale

**For Symmetry:**
- Redistribute paragraphs asymmetrically
- Key sections get more paragraphs, routine sections get fewer

## CONSTRAINTS:
1. Preserve all factual content and arguments
2. Maintain academic rigor and citation accuracy
3. Keep locked terms EXACTLY as listed
4. Output full modified document (not just changes)
5. Write in the same language as the original document

## OUTPUT FORMAT (JSON only):
{{
  "modified_text": "Full rewritten document with structural changes",
  "changes_summary_zh": "ä¸­æ–‡ä¿®æ”¹æ€»ç»“ï¼šåˆ—å‡ºå…·ä½“åšäº†å“ªäº›ç»“æ„è°ƒæ•´",
  "changes_count": number_of_structural_changes,
  "issues_addressed": ["issue types addressed"]
}}
```

#### Step 1.2: Paragraph Length Regularity æ®µè½é•¿åº¦è§„å¾‹æ€§

**ANALYSIS_PROMPT:**
```
You are an academic document paragraph length analyzer. Analyze PARAGRAPH LENGTH DISTRIBUTION only.

## DOCUMENT TEXT:
{document_text}

## YOUR TASK:

Calculate and analyze paragraph length distribution:

1. **Calculate CV (Coefficient of Variation)**
   - CV = (standard_deviation of word counts) / (mean word count)
   - AI-like: CV < 0.30 (too uniform)
   - Human-like: CV â‰¥ 0.40 (healthy variation)

2. **Detect Uniform Paragraph Length Pattern**
   - Check if most paragraphs fall within a narrow range (e.g., all 80-120 words)
   - AI-like: 80%+ paragraphs within Â±20% of mean
   - Human-like: Wide range from very short (30 words) to very long (200+ words)

3. **Identify Paragraphs Needing Adjustment**
   - Mark paragraphs that should be split (too long and monotonous)
   - Mark paragraphs that should be expanded (too short and underdeveloped)
   - Mark paragraphs that should be merged (fragmented logic)

## LOCKED TERMS:
{locked_terms}
Context: These terms will not be modified in rewriting.

## OUTPUT FORMAT (JSON only):
{{
  "issues": [
    {{
      "type": "uniform_length",
      "description": "Paragraph length variance too low (CV={cv_value})",
      "description_zh": "æ®µè½é•¿åº¦è¿‡äºå‡åŒ€ï¼ˆå˜å¼‚ç³»æ•°={cv_value}ï¼‰",
      "severity": "high|medium|low",
      "affected_positions": ["paragraph indices with uniform length"],
      "current_cv": 0.xx,
      "target_cv": 0.40,
      "split_candidates": ["para_index: reason"],
      "expand_candidates": ["para_index: reason"],
      "merge_candidates": [["para1_index", "para2_index", "reason"]]
    }}
  ],
  "risk_score": 0-100,
  "risk_level": "high|medium|low",
  "recommendations": ["English recommendations"],
  "recommendations_zh": ["ä¸­æ–‡å»ºè®®"]
}}
```

**REWRITE_PROMPT:**
```
You are an academic document paragraph length optimizer. Apply paragraph length adjustments to achieve natural variation while preserving content quality and locked terms.

## ORIGINAL DOCUMENT:
{document_text}

## SELECTED ISSUES TO FIX:
{selected_issues}

## USER'S ADDITIONAL GUIDANCE:
{user_notes}

## LOCKED TERMS (MUST PRESERVE):
{locked_terms}

## MODIFICATION STRATEGIES:

**Split Strategy (æ‹†åˆ†):**
- Break long paragraphs at natural topic shifts
- Create varied lengths: one long parent â†’ one short + one medium child

**Expand Strategy (æ‰©å±•):**
- Add concrete examples, case studies, or elaborations
- Avoid generic filler; add substantive content

**Merge Strategy (åˆå¹¶):**
- Combine fragmented paragraphs that discuss the same subtopic
- Create longer, cohesive paragraphs for key sections

**Target Distribution:**
- Short paragraphs: 30-60 words (10-20%)
- Medium paragraphs: 80-120 words (50-60%)
- Long paragraphs: 150-250 words (20-30%)
- Target CV â‰¥ 0.40

## CONSTRAINTS:
1. Preserve all factual content
2. Maintain logical flow
3. Keep locked terms EXACTLY as listed
4. Output full modified document

## OUTPUT FORMAT (JSON only):
{{
  "modified_text": "Full document with adjusted paragraph lengths",
  "changes_summary_zh": "ä¸­æ–‡ä¿®æ”¹æ€»ç»“ï¼šæè¿°æ‹†åˆ†/æ‰©å±•/åˆå¹¶çš„å…·ä½“æ“ä½œ",
  "changes_count": number_of_paragraphs_modified,
  "issues_addressed": ["uniform_length"],
  "new_cv": 0.xx
}}
```

#### Step 1.3: Progression Pattern & Closure æ¨è¿›æ¨¡å¼ä¸é—­åˆ

**ANALYSIS_PROMPT:**
```
You are an academic document progression analyzer. Analyze PROGRESSION PATTERN and CLOSURE STRENGTH only.

## DOCUMENT TEXT:
{document_text}

## YOUR TASKS:

1. **Detect Monotonic Progression (å•è°ƒæ¨è¿›)**
   - Check for linear, step-by-step topic advancement withoutå›æº¯
   - AI-like: Topic A â†’ Topic B â†’ Topic C (never revisits A or B)
   - Human-like: Topic A â†’ Topic B â†’ back to A with new insight â†’ Topic C

2. **Detect Too-Strong Closure (è¿‡åº¦é—­åˆ)**
   - Check for formulaic conclusion patterns
   - AI-like: "In conclusion, this study has shown...", "To summarize..."
   - Human-like: Open questions, unresolved tensions, future research needs

3. **Detect Missing Conditional/Qualification (ç¼ºå°‘æ¡ä»¶é™å®š)**
   - AI tends to make absolute statements
   - Human-like: "In certain contexts...", "Under these conditions...", "However..."

## LOCKED TERMS:
{locked_terms}

## OUTPUT FORMAT (JSON only):
{{
  "issues": [
    {{
      "type": "monotonic_progression|too_strong_closure|missing_qualification",
      "description": "English description",
      "description_zh": "ä¸­æ–‡æè¿°",
      "severity": "high|medium|low",
      "affected_positions": ["section or paragraph indices"],
      "evidence": "Specific text showing the pattern"
    }}
  ],
  "risk_score": 0-100,
  "risk_level": "high|medium|low",
  "recommendations": ["English recommendations"],
  "recommendations_zh": ["ä¸­æ–‡å»ºè®®"]
}}
```

**REWRITE_PROMPT:**
```
You are an academic document progression optimizer. Apply the following modifications to create more human-like argumentation flow while preserving locked terms.

## ORIGINAL DOCUMENT:
{document_text}

## SELECTED ISSUES TO FIX:
{selected_issues}

## USER'S ADDITIONAL GUIDANCE:
{user_notes}

## LOCKED TERMS (MUST PRESERVE):
{locked_terms}

## MODIFICATION STRATEGIES:

**For Monotonic Progression:**
- Addå›æº¯: After introducing Topic B, revisit Topic A with new perspective
- Add conditional logic: "In contrast to X, when Y conditions apply..."
- Introduce non-sequential discussion

**For Too-Strong Closure:**
- Soften conclusions: Replace "This proves..." with "This suggests..."
- Add open questions: "Future research should explore..."
- Leave some tensions unresolved

**For Missing Qualification:**
- Add hedging: "may", "appears to", "in most cases"
- Add contextual conditions: "Under these specific conditions..."
- Add counter-examples or exceptions

## CONSTRAINTS:
1. Preserve all core arguments and evidence
2. Maintain academic credibility
3. Keep locked terms EXACTLY as listed
4. Output full modified document

## OUTPUT FORMAT (JSON only):
{{
  "modified_text": "Full document with improved progression logic",
  "changes_summary_zh": "ä¸­æ–‡ä¿®æ”¹æ€»ç»“",
  "changes_count": number_of_modifications,
  "issues_addressed": ["issue types"]
}}
```

#### Step 1.4: Anchor Density é”šç‚¹å¯†åº¦

**ANALYSIS_PROMPT:**
```
You are an academic document anchor density analyzer. Analyze CONCRETE ANCHOR DENSITY only.

## DOCUMENT TEXT:
{document_text}

## YOUR TASK:

Count the density of concrete anchors (evidence that LLMs can't fabricate):

**Anchor Types:**
1. Decimal numbers: 14.2, 3.56, 0.82 (weight: 1.0)
2. Percentages: 50%, 14.2% (weight: 1.2)
3. Statistical values: p < 0.05, r = 0.82, t-test (weight: 1.5)
4. Citations: [1], (Smith, 2020), et al. (weight: 1.5)
5. Units/measurements: 5mL, 20Â°C, 3kg (weight: 1.3)
6. Chemical formulas: H2O, CO2, C6H12O6 (weight: 1.2)

**Density Calculation:**
- Weighted anchor count per 100 words
- AI hallucination risk:
  - Density < 5.0: High risk (vague, abstract)
  - Density 5.0-10.0: Medium risk
  - Density > 10.0: Low risk (å…·ä½“ã€å¯éªŒè¯)

**Identify Low-Density Paragraphs:**
- Mark paragraphs with density < 3.0 as high-risk AI filler

## LOCKED TERMS:
{locked_terms}

## OUTPUT FORMAT (JSON only):
{{
  "issues": [
    {{
      "type": "low_anchor_density",
      "description": "Paragraph {X} has very low anchor density ({density}), suggesting abstract AI filler",
      "description_zh": "æ®µè½{X}é”šç‚¹å¯†åº¦è¿‡ä½ï¼ˆ{density}ï¼‰ï¼Œç–‘ä¼¼AIç”Ÿæˆçš„æŠ½è±¡å¡«å……å†…å®¹",
      "severity": "high|medium|low",
      "affected_positions": ["paragraph indices"],
      "current_density": 0.xx,
      "target_density": 5.0,
      "missing_anchor_types": ["statistical_values", "citations"]
    }}
  ],
  "overall_density": 0.xx,
  "risk_score": 0-100,
  "risk_level": "high|medium|low",
  "recommendations": ["English recommendations"],
  "recommendations_zh": ["ä¸­æ–‡å»ºè®®"]
}}
```

**REWRITE_PROMPT:**
```
You are an academic document anchor enhancement expert. Add concrete, verifiable anchors to low-density paragraphs while preserving locked terms.

## ORIGINAL DOCUMENT:
{document_text}

## SELECTED ISSUES TO FIX:
{selected_issues}

## USER'S ADDITIONAL GUIDANCE:
{user_notes}

## LOCKED TERMS (MUST PRESERVE):
{locked_terms}

## MODIFICATION STRATEGIES:

**For Low Anchor Density:**
- Add specific numbers: Replace "many" with "73%", "most" with "85%"
- Add citations: Reference existing literature (user must verify)
- Add statistical evidence: p-values, correlation coefficients
- Add measurements: Specific quantities, temperatures, concentrations
- Replace vague statements with concrete examples

**WARNING:**
- Do NOT fabricate data or citations
- If specific values are unknown, use placeholders like "[AUTHOR, YEAR]" or "[XX%]"
- User must fill in real values

**Target Density:** â‰¥ 5.0 anchors per 100 words

## CONSTRAINTS:
1. Do NOT invent false data or citations
2. Use placeholders if specific values are unknown
3. Keep locked terms EXACTLY as listed
4. Output full modified document

## OUTPUT FORMAT (JSON only):
{{
  "modified_text": "Full document with added concrete anchors (use placeholders if needed)",
  "changes_summary_zh": "ä¸­æ–‡ä¿®æ”¹æ€»ç»“ï¼šæè¿°æ·»åŠ çš„é”šç‚¹ç±»å‹",
  "changes_count": number_of_anchors_added,
  "issues_addressed": ["low_anchor_density"],
  "new_overall_density": 0.xx,
  "placeholders_needing_verification": ["list of placeholders user must replace"]
}}
```

#### Step 1.5: Transitions & Connectors è¡”æ¥ä¸è¿æ¥è¯

**ANALYSIS_PROMPT:**
```
You are an academic document transition analyzer. Analyze PARAGRAPH TRANSITIONS and CONNECTOR USAGE only.

## DOCUMENT TEXT:
{document_text}

## YOUR TASKS:

1. **Detect Explicit Connectors at Paragraph Openings (æ˜¾æ€§è¿æ¥è¯)**
   - AI-like: "Furthermore, ...", "Moreover, ...", "Additionally, ...", "However, ..."
   - Human-like: Implicit semantic connection, lexical echoes

2. **Detect Formulaic Topic Sentences (å…¬å¼åŒ–ä¸»é¢˜å¥)**
   - AI-like: Every paragraph starts with "This study...", "The results show..."
   - Human-like: Varied sentence openers

3. **Detect Too-Smooth Transitions (è¿‡åº¦å¹³æ»‘è¿‡æ¸¡)**
   - AI-like: Every paragraph seamlessly connects with perfect logical flow
   - Human-like: Some abrupt topic shifts are natural

4. **Detect Summary Endings (å…¬å¼åŒ–æ€»ç»“ç»“å°¾)**
   - AI-like: Paragraphs end with "Thus, ...", "Therefore, ...", "In summary, ..."
   - Human-like: Varied endings, some abrupt

## LOCKED TERMS:
{locked_terms}

## OUTPUT FORMAT (JSON only):
{{
  "issues": [
    {{
      "type": "explicit_connector|formulaic_topic_sentence|too_smooth_transition|summary_ending",
      "description": "English description",
      "description_zh": "ä¸­æ–‡æè¿°",
      "severity": "high|medium|low",
      "affected_positions": ["paragraph indices or transition points"],
      "connector_word": "Furthermore|Moreover|...",
      "suggestion": "Replace with lexical echo or implicit connection"
    }}
  ],
  "connector_density": "X connectors per 100 words",
  "risk_score": 0-100,
  "risk_level": "high|medium|low",
  "recommendations": ["English recommendations"],
  "recommendations_zh": ["ä¸­æ–‡å»ºè®®"]
}}
```

**REWRITE_PROMPT:**
```
You are an academic document transition optimizer. Remove explicit connectors and create implicit semantic connections while preserving locked terms.

## ORIGINAL DOCUMENT:
{document_text}

## SELECTED ISSUES TO FIX:
{selected_issues}

## USER'S ADDITIONAL GUIDANCE:
{user_notes}

## LOCKED TERMS (MUST PRESERVE):
{locked_terms}

## MODIFICATION STRATEGIES:

**For Explicit Connectors:**
- Remove "Furthermore", "Moreover", "Additionally"
- Replace with lexical echoes: Repeat key term from previous paragraph
- Example:
  - Before: "Para 1 discusses X. Furthermore, para 2 discusses Y."
  - After: "Para 1 discusses X. The concept of X also applies to Y."

**For Formulaic Topic Sentences:**
- Vary sentence openers: Some start with prepositional phrases, adverbs, or subordinate clauses
- Avoid repetitive patterns like "This study...", "The results..."

**For Too-Smooth Transitions:**
- Allow some abrupt topic shifts (natural in human writing)
- Not every paragraph needs explicit connection

**For Summary Endings:**
- Remove "Thus", "Therefore", "In summary"
- Use varied endings or even abrupt stops

## CONSTRAINTS:
1. Preserve all arguments and logic
2. Maintain paragraph meaning
3. Keep locked terms EXACTLY as listed
4. Output full modified document

## OUTPUT FORMAT (JSON only):
{{
  "modified_text": "Full document with improved transitions",
  "changes_summary_zh": "ä¸­æ–‡ä¿®æ”¹æ€»ç»“ï¼šæè¿°åˆ é™¤çš„è¿æ¥è¯å’Œä½¿ç”¨çš„è¯­ä¹‰å›å£°",
  "changes_count": number_of_transitions_modified,
  "issues_addressed": ["issue types"],
  "connectors_removed": ["list of removed connectors"]
}}
```

---

### Layer 4 (Section Level) - ç« èŠ‚çº§

#### Step 2.0: Section Identification ç« èŠ‚è¯†åˆ«

**ANALYSIS_PROMPT:**
```
You are an academic document section analyzer. Identify sections and their roles.

## DOCUMENT TEXT:
{document_text}

## YOUR TASKS:

1. **Identify Section Boundaries**
   - Detect section headers (e.g., "1. Introduction", "2.1 Methods")
   - If no explicit headers, infer sections based on topic shifts

2. **Label Section Roles**
   - introduction, literature_review, methodology, results, discussion, conclusion
   - Or custom roles if non-standard structure

3. **Count Paragraphs Per Section**

4. **Detect Issues**
   - All sections have same number of paragraphs (symmetry issue)
   - Missing critical sections
   - Unconventional section order

## LOCKED TERMS:
{locked_terms}

## OUTPUT FORMAT (JSON only):
{{
  "sections": [
    {{
      "number": "1",
      "title": "Introduction",
      "role": "introduction",
      "paragraph_count": 3,
      "paragraph_indices": [0, 1, 2]
    }}
  ],
  "issues": [...],
  "risk_score": 0-100,
  "risk_level": "high|medium|low",
  "recommendations": ["English"],
  "recommendations_zh": ["ä¸­æ–‡"]
}}
```

**REWRITE_PROMPT:**
```
You are an academic document section organizer. Reorganize sections to address identified issues while preserving locked terms.

## ORIGINAL DOCUMENT:
{document_text}

## SELECTED ISSUES TO FIX:
{selected_issues}

## USER'S ADDITIONAL GUIDANCE:
{user_notes}

## LOCKED TERMS (MUST PRESERVE):
{locked_terms}

## MODIFICATION STRATEGIES:

**For Section Symmetry:**
- Redistribute paragraphs asymmetrically
- Key sections get more content, routine sections get less

**For Missing Sections:**
- Add placeholder or merge with existing sections

**For Unconventional Order:**
- Reorder if user requests, but preserve logical flow

## CONSTRAINTS:
1. Preserve all content
2. Keep locked terms EXACTLY as listed
3. Output full modified document with clear section headers

## OUTPUT FORMAT (JSON only):
{{
  "modified_text": "Full document with reorganized sections",
  "changes_summary_zh": "ä¸­æ–‡ä¿®æ”¹æ€»ç»“",
  "changes_count": number_of_sections_modified,
  "issues_addressed": ["issue types"]
}}
```

#### Step 2.1-2.5: Other Section-Level Substeps

ï¼ˆç±»ä¼¼è®¾è®¡ï¼Œåˆ†æç« èŠ‚é¡ºåºã€ç« èŠ‚é•¿åº¦ã€ç« èŠ‚å†…é€»è¾‘ç­‰ï¼‰

---

### Layer 3 (Paragraph Level) - æ®µè½çº§

#### Step 3.0: Paragraph Identification æ®µè½è¯†åˆ«

**ANALYSIS_PROMPT:**
```
You are an academic document paragraph analyzer. Identify paragraphs and filter non-body content.

## DOCUMENT TEXT:
{document_text}

## YOUR TASKS:

1. **Split Text into Paragraphs**
   - Use double newline as delimiter

2. **Filter Non-Body Content**
   - Remove: Abstract headers, Keywords, Figure captions, Table content, References
   - Keep: Only real prose paragraphs

3. **Label Each Paragraph**
   - paragraph_index
   - word_count
   - sentence_count
   - is_body_content: true/false

4. **Detect Issues**
   - Too many non-body paragraphs (needs cleaning)

## OUTPUT FORMAT (JSON only):
{{
  "paragraphs": [
    {{
      "index": 0,
      "text": "paragraph text...",
      "word_count": 120,
      "sentence_count": 5,
      "is_body_content": true
    }}
  ],
  "body_paragraph_count": 15,
  "filtered_paragraph_count": 3,
  "issues": [...],
  "risk_score": 0-100
}}
```

**REWRITE_PROMPT:**
ï¼ˆæ®µè½è¯†åˆ«ä¸éœ€è¦æ”¹å†™ï¼Œåªéœ€è¦æ¸…ç†ï¼‰

#### Step 3.1-3.5: Other Paragraph-Level Substeps

ï¼ˆæ®µè½è§’è‰²æ ‡æ³¨ã€æ®µå†…è¿è´¯æ€§ã€é”šç‚¹å¯†åº¦ã€å¥é•¿åˆ†å¸ƒã€æ®µè½è¿‡æ¸¡ç­‰ï¼‰

---

### Layer 2 (Sentence Level) - å¥å­çº§

#### Step 4.0: Sentence Identification å¥å­è¯†åˆ«

**ANALYSIS_PROMPT:**
```
Identify sentences within paragraphs and label their types (simple, complex, compound, compound-complex).

Detect issues:
- Too many simple sentences
- Too few complex sentences
- Repetitive sentence openers
```

#### Step 4.1-4.5: Other Sentence-Level Substeps

ï¼ˆå¥é•¿åˆ†æã€å¥å­åˆå¹¶ã€è¿æ¥è¯ä¼˜åŒ–ã€å¥å¼å¤šæ ·åŒ–æ”¹å†™ç­‰ï¼‰

---

### Layer 1 (Lexical Level) - è¯æ±‡çº§

#### Step 5.0: Lexical Context Preparation è¯æ±‡ç¯å¢ƒå‡†å¤‡

**ANALYSIS_PROMPT:**
```
Analyze vocabulary richness and word frequency distribution.

Detect issues:
- Low vocabulary diversity (vocabulary_richness < 0.3)
- Over-use of certain words
```

#### Step 5.1: AIGC Fingerprint Detection AIGCæŒ‡çº¹æ£€æµ‹

**ANALYSIS_PROMPT:**
```
Detect AI fingerprint words and phrases.

AI fingerprint categories:
- Overused words: delve, underscore, leverage, harness, pivotal
- Formulaic phrases: "In the realm of", "It is worth noting that"
- Absolute modifiers: "comprehensive", "robust", "significant"
```

#### Step 5.2-5.5: Other Lexical-Level Substeps

ï¼ˆäººç±»ç‰¹å¾åˆ†æã€æ›¿æ¢å€™é€‰ç”Ÿæˆã€LLMæ®µè½çº§æ”¹å†™ã€æ”¹å†™ç»“æœéªŒè¯ï¼‰

---

## å››ã€é€šç”¨Promptæ¨¡æ¿å˜é‡ | Generic Prompt Template Variables

æ‰€æœ‰promptéƒ½åº”è¯¥æ”¯æŒä»¥ä¸‹å˜é‡ï¼š

```python
# åˆ†æPromptå˜é‡ | Analysis Prompt Variables
{
    "document_text": str,  # å½“å‰æ–‡æ¡£æ–‡æœ¬ï¼ˆå¯èƒ½æ˜¯å‰ä¸€æ­¥çš„ä¿®æ”¹ç»“æœï¼‰
    "locked_terms": List[str],  # Step 1.0é”å®šçš„æœ¯è¯­
    "session_id": str,  # ä¼šè¯ID
    "colloquialism_level": int  # å£è¯­åŒ–çº§åˆ«ï¼ˆæŸäº›æ­¥éª¤éœ€è¦ï¼‰
}

# æ”¹å†™Promptå˜é‡ | Rewrite Prompt Variables
{
    "document_text": str,
    "selected_issues": List[SelectedIssue],  # ç”¨æˆ·é€‰ä¸­çš„é—®é¢˜
    "user_notes": str,  # ç”¨æˆ·çš„é¢å¤–æŒ‡å¯¼æ„è§
    "locked_terms": List[str],
    "colloquialism_level": int,
    "previous_modifications": str  # å‰é¢æ­¥éª¤çš„ä¿®æ”¹å†å²ï¼ˆå¯é€‰ï¼‰
}
```

---

## äº”ã€Implementation Plan å®æ–½è®¡åˆ’

### Phase 1: å¤ç”¨æ—§ä»£ç schemas âœ…
- [x] ä½¿ç”¨ `SelectedIssue`, `MergeModifyRequest` ç­‰æ—§schemas
- [x] æ¯ä¸ªsubstepåªéœ€è¦å®šä¹‰è‡ªå·±çš„issue types

### Phase 2: å®ç°é€šç”¨substep APIæ¡†æ¶
- [ ] åˆ›å»º `BaseSubstepHandler` åŸºç±»
- [ ] å®šä¹‰3ä¸ªæ ‡å‡†ç«¯ç‚¹ï¼š
  - `POST /analyze` - åˆ†æ
  - `POST /merge-modify/prompt` - ç”Ÿæˆprompt
  - `POST /merge-modify/apply` - AIä¿®æ”¹

### Phase 3: ä¸ºæ¯ä¸ªsubstepç¼–å†™prompts
- [ ] Layer 5: Steps 1.1-1.5
- [ ] Layer 4: Steps 2.0-2.5
- [ ] Layer 3: Steps 3.0-3.5
- [ ] Layer 2: Steps 4.0-4.5
- [ ] Layer 1: Steps 5.0-5.5

### Phase 4: æµ‹è¯•ç«¯åˆ°ç«¯æµç¨‹
- [ ] æµ‹è¯•å®Œæ•´5å±‚æµç¨‹
- [ ] éªŒè¯locked_termsåœ¨æ‰€æœ‰æ­¥éª¤ä¸­è¢«ä¿ç•™
- [ ] éªŒè¯æ¯ä¸€æ­¥åŸºäºä¸Šä¸€æ­¥çš„ä¿®æ”¹ç»“æœ

---

## å…­ã€å…³é”®è®¾è®¡åŸåˆ™ | Key Design Principles

1. **èŒè´£å•ä¸€**: æ¯ä¸ªsubstepçš„åˆ†æpromptåªåˆ†æå½“å‰æ­¥éª¤çš„ç‰¹å®šé—®é¢˜
2. **ä¼ é€’ä¿®æ”¹**: æ¯ä¸ªsubstepæ¥æ”¶ä¸Šä¸€æ­¥çš„modified_textä½œä¸ºè¾“å…¥
3. **ä¿æŠ¤é”å®šè¯**: æ‰€æœ‰æ”¹å†™promptå¿…é¡»åŒ…å«locked_termsä¿æŠ¤
4. **ç»“æ„åŒ–è¾“å‡º**: æ‰€æœ‰LLMè¾“å‡ºå¿…é¡»æ˜¯JSONæ ¼å¼ï¼Œä¾¿äºå‰ç«¯è§£æ
5. **åŒè¯­æ”¯æŒ**: descriptionå’Œdescription_zhéƒ½è¦æœ‰
6. **ç”¨æˆ·å¯æ§**: ç”¨æˆ·å¯é€‰æ‹©é—®é¢˜ã€è¾“å…¥æŒ‡å¯¼æ„è§ã€ä¸Šä¼ æ–°æ–‡ä»¶

---

## ä¸ƒã€ä¸‹ä¸€æ­¥ | Next Steps

1. **åˆ›å»ºBaseSubstepHandleråŸºç±»**
2. **å®ç°Layer 5 Step 1.1ä½œä¸ºpilot**
3. **æµ‹è¯•å®Œæ•´æµç¨‹**
4. **å¤åˆ¶æ¨¡æ¿åˆ°å…¶ä»–substeps**

---

**END OF DOCUMENT**
